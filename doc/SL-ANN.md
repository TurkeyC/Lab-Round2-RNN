# 人工神经网络的监督学习

何毓辉

he.yuhui.ime@gmail.com

2022年11月1日

# 目录

# 1 单层神经网络 3

1.1 算法原理 3

1.1.1 误差极小化与梯度下降 3  
1.1.2 训练与测试：泛化能力 6  
1.1.3 在线学习与批量学习 10  
1.1.4 随机梯度下降 12  
1.1.5 权重更新：delta法则与曼哈顿法则 14

1.2 基于1T1M的突触阵列：人脸识别 15

1.2.1 输入/输出编码 15  
1.2.2 前向过程 16  
1.2.3 权重更新：写验证与写不验证 17  
1.2.4 忆阻突触器件：理想与现实 21

1.3 基于忆阻器差分对的突触阵列：三宫格识别 23

1.3.1 带偏置项的输入编码 23  
1.3.2 负权重实现：差分对方案 24  
1.3.3 阵列级权重更新方案 24  
1.3.4 训练结果与讨论 26

# 2 深度神经网络 27

2.1 算法原理：误差的反向传播 27  
2.2 反向传播的忆阻交叉阵列实现 30  
2.3 忆阻突触的非理想效应与对策 35

2.3.1 忆阻突触的非理想特性 35  
2.3.2 基于非易失存储器差分对的人工突触及操作设计 36  
2.3.3 实验与仿真结果讨论 42

# 3 本章小结 45

# 参考文献 48

# 1 单层神经网络

# 1.1 算法原理

如图1.1所示，首先是将样本  $S(t)$  编码为神经网络的输入电压矢量  $\{V_{i}\}$ ，经过输入层与输出层之间的突触矩阵  $W$ ，得到电流矢量  $\{I_j\}$ ：

$$
I _ {j} = \sum_ {i} V _ {i} w _ {i j} \tag {1.1}
$$

再经过输出层的激活函数  $f$  得到输出矢量  $\{f_j\}$

$$
f _ {j} = f \left(I _ {j}\right) \tag {1.2}
$$

它与期望值(desired value)  $\{f_{j}^{d}\}$  之间存在偏差，该偏差可以写成一个矢量 $(\vec{f} -\vec{f}^{d})$  。监督学习的核心任务就是如何最小化这个偏差。

# 1.1.1 误差极小化与梯度下降

一种常见的误差极小化方法是梯度下降(gradient descend, GD)：首先定义上述偏差矢量的二范数（也就是该矢量长度）的平方为误差：

$$
\begin{array}{l} E = \frac {\left\| \vec {f} - \vec {f} ^ {d} \right\| _ {2} ^ {2}}{2} \tag {1.3} \\ = \frac {\sum_ {j} (f _ {j} - f _ {j} ^ {d}) ^ {2}}{2} \\ \end{array}
$$

在给定输入矢量  $\vec{V}$  的情况下，期望输出矢量  $\vec{f}^d$  也是确定的，因此误差  $E$  是突触矩阵  $W$  的函数，如图1.2所示，求解  $E$  的最小化也就是寻找高维空间里  $E(W)$  曲面的最小值点。

假设神经网络的初始权重为  $W_{0}$ ，如图1.2所示，我们是从曲面的一点 $E_0(W_0)$  出发，寻找极小值点。从高等数学知识我们知道，  $\frac{\partial E}{\partial W}|_{W = W_0}$  代表曲面在这一点的切线方向，而如果沿着切线反方向行走，就是曲面的下降方向了。这就是下式梯度下降的由来：

![](images/4c6a08f0cb9c4e834e17304debd12d9a313a7f51afbbdbf21cc4282b46d6a8eb.jpg)  
图1.1：人工神经网络监督学习原理。第  $i$  个训练样本(trainingsample)的数据  $\vec{S}_i(t)$  经过编码成为神经网络输入层的电压矢量  $\vec{V}$ ，而从输入层到输出层的连接是一个电导矩阵  $W$ ，因此输入电压矢量  $\vec{V}$  经过电导矩阵转变为输出层的电流矢量  $\vec{I}$ ，再经过激活函数  $f$  处理，最终得到输出矢量  $\vec{f}$ ；然而针对第  $i$  个样本，神经网络有一个期望(desired)的输出矢量  $\vec{f}^d$ ；于是定义误差为实际输出矢量与期望值的差距大小的平方  $E = |\vec{f} -\vec{f}^d |^2$ ，接下来通过更新连接权重的大小将误差极小化，用到的算法是梯度下降。

![](images/4713409b32c17c17b2127ea192ac61c83f066293778b3944291cc464eab50029.jpg)  
图1.2: 高维空间误差函数曲面示意图。高维空间的  $E(w_{ij})$  曲面示意图, 其中  $E$  是由公式1.3定义的误差标量,  $w_{ij}$  是神经网络突触权重矩阵的每一个元素。该曲面存在一个或者多个极小值点, 假设系统初始位置在  $E_0(W_0)$ , 那么不停地沿着曲面的切线反方向小步行走, 总可以到达一个极小值点。

$$
\begin{array}{l} \Delta w _ {i j} = - \eta \frac {\partial E}{\partial w _ {i j}} \\ = - \eta \frac {\partial E}{\partial f _ {j}} \frac {\partial f _ {j}}{\partial I _ {j}} \frac {\partial I _ {j}}{\partial w _ {i j}} \tag {1.4} \\ = - \eta (f _ {j} - f _ {j} ^ {d}) f _ {j} ^ {\prime} (I _ {j}) V _ {i} \\ \end{array}
$$

其中， $\eta$  是学习率(learning rate)，由图1.2可知，它定义的是梯度下降算法的步长。

上式的数学推导在物理上含义是很清晰的：当连接输入层第  $i$  个神经元与输出层第  $j$  个神经元的突触权重发生变化  $\Delta w_{ij}$ ，它首先会引起相应的输入电压  $V_{i}$  向后级传导的电流变化  $\Delta I_{j}$ ，进而影响输出层第  $j$  个神经元的激活函数变化  $\Delta f_{j}$ ，根据误差定义， $E$  也会产生相应变化  $\Delta E$ 。

$$
\Delta w _ {i j} \rightarrow \Delta I _ {j} \rightarrow \Delta f _ {j} \rightarrow \Delta E
$$

公式1.4最后表达式指出：在监督学习算法里，神经网络突触权重的改变量是正比于两个量的，一个是实际输出与期望值之间的偏差  $(f_{j} - f_{j}^{d})$ ，另一个是输入的幅度  $V_{i}$ 。

上述结论是符合物理直觉的。首先，实际输出与期望值之间的偏差越大，意味着神经网络突触的初始权重设置离“正确值”越远，因此需要的权重改变量越大。随着训练一轮一轮进行，这个偏差应该越来越小，于是相应的权重改变量也越来越小，直到偏差可忽略不计  $|f_{j} - f_{j}^{d}| < \epsilon$  ，相应的神经网络权重也就不再需要调整了  $\Delta w_{ij} \approx 0$  。

其次，从神经网络连接的角度看，输入  $V_{i}$  幅度越大，它通过突触  $w_{ij}$  对输出  $f_{j}$  的贡献也就越大，在这种情况下，大幅度调整这个连接的权重，有利于将偏差  $(f_{j} - f_{j}^{d})$  减小。而当输入  $V_{i}$  幅度很小，例如在最极端的情况下  $V_{i} = 0$ ，那么  $V_{i}$  通过突触  $w_{ij}$  传给后一级  $I_{j}$  的贡献基本可以忽略，这个时候假如实际输出  $f_{j}$  仍然对期望值  $f_{j}^{d}$  有不可忽略的偏差，说明这个偏差  $(f_{j} - f_{j}^{d})$  不是  $V_{i}$  贡献的，而是其它输入  $V_{i'} (i' \neq i)$  贡献的。这种情况下，调整连接前一层第  $i$  个神经元与后一层第  $j$  个的突触权重  $w_{ij}$  是没有意义的。

另外，在后续章节中，我们将一再看到，公式1.4描述的权重更新取决于哪两个物理量是监督学习算法下的普适结论，跟神经网络采取模拟值编码还是脉冲发放时刻编码等无关；而对于更复杂的多层神经网络训练即深度学习，其权重更新在数学形式上也是符合上述原则的。

# 思考题：

1. 公式1.4中的学习率  $\eta$  取值过小或者过大，在实际权重更新操作中会有什么问题？  
2 仔细观察图1.2与公式1.4，不难发现，当初始权重取值不同时，最终收敛到的“谷底”是不同的。换句话说，公式1.4筛选出来的实际上是局域的极小值点(local minimum point)，而非全局最小值点(global minimum point)。严格意义上，我们要求的是后者，而公式1.4给出的是前者。这样的处理会有什么问题？你认为有哪些可能的优化方案？

# 1.1.2 训练与测试：泛化能力

在完成训练以后，通常要用训练时没出现过的样本来测试神经网络。这实际上考察的是神经网络的泛化能力(generalization)。

![](images/d00261c292dd235828f4d478ac63484a7709101c0e90735df27933fb326a7e6b.jpg)  
图1.3: 用于猫狗图像分类的神经网络。前半部分用于特征提取, 后半部分用于分类。当网络训练完成之后, 输入狗的图片 (图左), 特征提取层负责识别鼻子 (nose) 和脸型 (face) 的部分会提取图片中相应部分, 接下来编码狗的鼻子和脸型的神经元会响应, 同时将信号传递到分类层。由于分类层经过训练后编码狗的特征的神经元与代表狗的输出神经元权重连接更大（图中的连接线更粗）, 因此最终代表狗的输出神经元会响应, 网络将图片识别为狗。当输入图片为猫时情况类似, 参见图右。

![](images/f7d976b2154b1d70b7c7aa6fa03b576b887b26863c306ef270efabe8d7ca774d.jpg)

举一个简单例子，假设我们构建如图1.3所示的神经网络，它的前半部分用于特征提取 feature extraction)，而后半部分用于分类(classification)。现在给该网络投喂猫、狗图片各1000张，训练它两个输出神经元分别对猫、狗图像响应。

如图所示，理想的情况是，经过训练，特征提取层获得了猫跟狗区分度最大的若干信息，例如猫是圆而扁平的脸、鼻子占面部比例较小且胡须长度跟脸的宽度有一个比值，而狗是方而突出的脸、鼻子占脸比例很大且没有明显胡须；接下来，编码猫这些特征的神经元与代表猫的输出神经元连接权重很大，而与代表狗的输出神经元连接权重较小；而编码狗特征的神经元与上述两个输出神经元的连接权重则与之相反。

当我们把神经网络没有见过的一张新图片输入，会发生什么呢？注意世界上没有长得一模一样的猫，即使是同一只猫，不同时刻拍摄的照片里外形仍会有差别。因此，首先特征提取层会判断该神经网络已经学习到的猫/狗各项特征跟测试图片中相关片段的吻合度。如图所示，随后各个特征的吻合度数据通过输出层的连接权重向两个输出神经元汇总，引发它们不

同程度的响应，据此推断输入图片是猫还是狗。

从上述例子我们可以逆向思考，假如一个神经网络明明训练通过了，测试效果却很差，问题可能出在哪些地方？

一种可能是神经网络的分类层要求特别严格。例如它要求测试图像必须同时具有圆脸、小鼻子、胡须长度跟脸的宽度比为1.5，且每项特征吻合度大于  $90\%$  。这种情况下，假如测试图片里是一只玩火时不幸被燎了半边胡须的猫，判别为猫的输出层神经元就无法响应。

另一种可能是神经网络“偷懒”了，它为了迎合训练样本而投机取巧了。例如它实际上仅仅训练出识别狗特征的能力，而把非狗的特征统统塞给猫了。对于非猫即狗的训练数据来说，这种“作弊”在训练阶段是能够通过的。而且因为不需要训练识别猫的特征，这种神经网络比我们真实期望的那种收敛还要快很多。但假如测试图片是一张猪的图片，那么这种“偷懒”的神经网络就会原形毕露了：它会指“猪”为“猫”。

上述分析实际上是以实例指出，神经网络的泛化能力既可能被过拟合(overfitting)、也可能被欠拟合(underfitting)劣化。

以上对泛化能力的分析，也可以从纯粹数学的角度理解。如图1.4所示，每一个输入样本可以用高维空间的一个点来表示，那么全部输入样本就构成了高维空间的一朵数据云，而代表猫和狗的数据点分别标红和蓝。所谓训练，其实就是通过调整权重参数，使函数  $f(\vec{V}, W)$  能更有效地“切割”图中的红点和蓝点区域。

相应地，神经网络的泛化能力就很清楚地显示出来了：真实世界里，训练样本的采集是很昂贵的*，因此它的数目是很有限的，表现在数据空间里，由带标签的训练数据构成的数据云总体来说是体积很小且很稀疏的。而据此训练出来“切割”数据云的函数能够对没有被训练样本点密集覆盖到的区域也做出有效判断，这就是泛化。

总的来说，神经网络的泛化能力可以说是使用神经网络来解决问题的

![](images/62c3cc673347359091291f637d2a83330fa32f8676eba003da4943812d231139.jpg)  
图1.4: 二维空间中样本分布以及神经网络训练收敛示意图。横纵坐标轴分别代表用来分辨猫狗的两种特征参数  $\theta_{1}$  和  $\theta_{2}$ , 红蓝色点分别代表猫、狗的样本分布, 虚线和直线代表神经网络在此二维平面上拟合的函数  $f(\vec{V}, W)$  。网络初始化之后的  $f(\vec{V}, W)$  如最左侧虚线所示, 此时并不能很好地对红蓝两种样本进行有效分割。而经过不断训练, 网络权重调整之后,  $f(\vec{V}, W)$  的收敛过程如箭头所示, 最终收敛到最右侧实线状态, 以理想的状态对红蓝两种样本进行分割。

核心优势，对它的讨论意义重大，感兴趣的读者可以进一步参考麻省理工学院Chiyuan Zhang等人的论文[1, 2]。

思考题：上述神经网络例子里，对于猫和狗共性的特征，例如都有四条腿，该特征对区分猫/狗没有贡献，那么你认为神经网络在训练阶段是怎么处理这个特征的呢？是在特征提取层就不提取该特征，还是在分类层降低该特征对输出的权重贡献？

# 1.1.3 在线学习与批量学习

如前所述，假如有多个训练样本，那么在训练阶段就有不同的学习策略：

# 1 在线学习(online learning)

每输入一个样本，神经网络学习完毕以后，再输入下一个，如此循环往复，直到全部样本学习完毕。

# 2 批量学习(batch learning)

假设总共有  $N$  个训练样本，将第  $n$  个样本编码输入  $\{V_{i}^{(n)}\}$ ，按照公式1.4算出来的权重更新为  $\Delta_{ij}^{(n)} = -\eta (f_j - f_j^d)f_j'(I_j)V_i^{(n)}$ 。

而批量学习并不当场更新神经网络的权重，而是将  $N$  个样本全部输入一遍，计算出所有的  $\Delta_{ij}^{(n)}$ ，把它们的累加结果作为权重更新：

$$
\Delta w _ {i j} = \sum_ {n = 1} ^ {N} \Delta_ {i j} ^ {(n)} \tag {1.5}
$$

# 两种策略的比较

首先，虽然在线学习也是大循环嵌套小循环，但它的大循环并不是针对  $N$  个输入样本总共循环  $N$  次就可以。原因是，假设神经网络针对第  $i$  个样本训练完成，当它开始训练第  $i + 1$  个时，神经网络的权重又被修改了，意味着先前针对第  $i$  个样本的优化被覆盖掉了。因此，理论上需要将  $N$  个样本反复循环输入，直到误差对全部  $N$  个样本都被控制在一个可接受的范围内。

![](images/b4f8ba07978feb152be73fcb894d60879d460eb2630a69129a50e0d4bd3b6fee.jpg)  
图1.5：在线学习过程中的权重变化。初始化的权重为  $W_{0}$ ，当输入第一个样本时，其关于权重的误差曲线表示为  $E_{1}(W)$ ，则根据梯度下降的法则，权重将从  $W_{0}$  收敛到  $E_{1}(W)$  的最低点处，也就是  $W_{1}^{*}$  处。当再输入第二个样本时，同样地权重会收敛到  $E_{2}(W)$  的最低点  $W_{2}^{*}$ ，之后输入的样本同理。

从数学原理上，如图1.5所示，在最简单的一维数据空间里，每一个样本都有一个  $E(W)$  曲线。在线学习的内层循环可以形象地理解为在其中一个曲线上寻找附近的极值点，而外层循环则是在这  $N$  个曲线函数的极值点之间跳来跳去，寻找能够接受的“公共”最低点。

以上分析是可以直接推广到真实案例的高维数据空间，相应的每一个样本有一个  $E(W)$  曲面函数。

其次，在线学习的效果对样本的输入顺序有强烈的依赖。这一点也可以从图1.5清楚地看到：首先输入的是哪一张图片，意味着整个神经网络是为了具体这张图片的学习而优化的，数学上就是神经网络的权重落入到某一个点附近  $W'$  。这一点可能离全部图片的“公共”最低点很近，也可能很远。其次，样本序列本身在采集时有可能是有一定规律和联系，而不是完全随机的，那么对后续样本的学习，权重仍然在  $W'$  附近徘徊，可能并不向全局最低点迈进。

最后，可以看到批量学习的实际更新权重操作要少了很多。这一点在神经网络规模很大、样本数量很大的实际应用中是比较重要的。

思考题：对比在线学习与批量学习，你认为哪一种学习方式更接近生物脑？两种方式各自的优缺点又是什么呢？

# 1.1.4 随机梯度下降

观察批量学习的权重更新公式1.5，不难发现，由于每个样本的梯度在更新时均被计算，因此批量梯度下降是朝着全局最优解的方向计算的。但是每迭代一步，均需要计算所有的样本梯度，如果样本数过大，将会导致训练过程异常缓慢。

有鉴于此，随机梯度下降(stochastic gradient descend，SGD)被提了出来。在随机梯度下降中，每次迭代均从所有样本中随机抽取一个样本计算其梯度，并据此更新权重，其数学形式如下：

$$
\Delta w _ {t} = - \eta \nabla E _ {i} (w) \tag {1.6}
$$

其中， $\nabla$  是求梯度（gradient）算子。在样本量巨大的情况下，由于其抽取样本的随机性，随机梯度下降可以保证在前期的训练过程中每次迭代权重

均有较大的更新量，因此能更快地收敛。与批量梯度下降方案相比，面对巨量的样本，随机梯度下降大部分情况下只需要遍历整体样本的一部分便可完成训练，而前者则需要将所有样本遍历几十遍才可收敛。

![](images/5512ba00af8ad5b85f5b6d54c295654d74772f5491f7610157564a5cd8a331f7.jpg)  
图1.6：全样本的梯度下降与随机梯度下降对比。在所有样本的梯度“等高线”分布图中，梯度下降方案中每次迭代均沿着整体梯度方向下降，目标明确；随机梯度下降因其随机抽取样本计算其梯度的特点，并不能保证每次均沿整体梯度方向下降，但整体收敛的趋势仍然是与梯度下降一致的。

如图1.6所示，批量梯度下降在训练过程中整体目标明确，朝着全局梯度的方向下降，而随机梯度下降的优化过程则显得更曲折，但最终也可达到收敛。而对随机梯度下降来说，训练速度的增加则是以牺牲准确度为代价的，其随机抽取单样本的特性决定了其并非每次均朝着全局最优的方向演变，因此其收敛效果是弱于批量梯度下降的。

对比以上批量梯度下降和随机梯度下降两种方案，可以得到如下结论：前者的优点在于可以得到全局最优解，但相应的收敛速度大打折扣；后者则可以大幅提升收敛速度，相应地会牺牲一定准确度，无法精确达到全局最优解。

不难看出来这里是一个训练速度与准确度的折中(trade off)，那么自然而然地，如果把以上两种方案看作这里权衡的两个极端方向，能否找到一个折衷的方案？因此人们提出小批量梯度下降(mini-batch gradient descent，

MBGD)的思想。

小批量梯度下降的出发点是训练的速度较快，同时也要保证最终参数收敛的准确度率。其做法可以从上述两种“极端”操作中显而易见得到：每次迭代过程从所有样本中随机抽取小批量(mini-batch)个样本，计算这些样本的梯度来更新权重，其数学形式如下：

$$
\Delta w _ {t} = - \eta_ {t} \left(\sum_ {i = 1} ^ {\text {m i n i - b a t c h}} \nabla E _ {i} (w)\right) \tag {1.7}
$$

小批量梯度下降的物理含义结合上述两种梯度下降方案很容易理解，这里不再赘述。

如今，随着人们对神经网络调参技术的愈发娴熟，全样本的批量梯度下降方法已经被彻底抛弃，较为完善的小批量梯度下降已经成为主流的方案，通常提到的随机梯度下降均指小批量梯度下降。

# 思考题：

1 如何理解“随机梯度下降”里的“随机”？  
2 如果在神经网络的训练过程中，网络在梯度下降过程中遇到了鞍点或者局部最低点，这些位置的梯度均为0，那么这时候批量梯度下降、随机梯度下降、小批量梯度下降分别会使网络的权重参数怎样变化？你认为有什么办法可以解决或者避免这样的问题？

# 1.1.5 权重更新：delta法则与曼哈顿法则

按照公式1.4或1.5算出权重应该改变的量  $\Delta W$  以后，有两种突触更新策略：

# 1 delta法则 (delta rule)

根据公式1.4算出来突触权重修正量是多少，实际就改变多少。

# 2 曼哈顿法则(Manhattan rule)

以批量学习为例，曼哈顿法则如下处理：

$$
w _ {i j} = \Delta w _ {0} \operatorname {s g n} \left(\sum_ {n = 1} ^ {N} \Delta_ {i j} ^ {(n)}\right) \tag {1.8}
$$

其中，sgn是符号函数，而  $\Delta w_{0}$  是固定的步长。该法则指出，无论算出来的权重更新值大小是多少，这里只关心更新值的正负，是正的则突触权重增加一个步长，反之减少一个。

# delta法则与曼哈顿法则的比较

乍一看，曼哈顿法则比较莫名其妙，明明每次算出来突触权重的改变量是不同的数值，为什么更新的时候统一为一个幅值？

但实际上，曼哈顿法则是硬件友好型(hardware friendly)法则。对于真实的忆阻突触器件，由于其内禀的电导调制随机性等问题，几乎不可能用很有限的硬件电路和时间代价来实现公式1.4要求的权重更新。曼哈顿法则指出，不管计算出来的权重要增加/减少多少，实际更新只执行一步置态/重置操作。后续章节将结合忆阻突触器件实例来详细讨论曼哈顿法则的优势以及问题。

# 1.2 基于1T1M的突触阵列：人脸识别

2017年，清华大学钱鹤与吴华强教授团队提出一种基于1晶体管1忆阻器（1 transistor 1 memristor，1T1M）的仿生突触器件，并实验制备了1K规模（ $32 \times 32$ ）的忆阻突触阵列，在此基础上，他们构建了由320个输入、3个输出组成的全连接神经网络，并成功展示了该网络的人脸识别功能[3,4]。

本节按照忆阻神经网络（memristive neural network）的一般设计流程，从输入/输出编码开始，到神经网络运行的前向操作，到突触权重更新设计，逐项分析讲解上述工作，重点关注该工作针对忆阻突触非理想特性在更新操作层面的创新。

# 1.2.1 输入/输出编码

# 一、输入编码

对于如图1.7左边所示的人脸图片，首先将其划分为  $16 \times 20 = 320$  个像素点，因此需要320个输入神经元来编码，如图1.7右边电路所示，该1T1M阵列设置了320根位线(bitline，BL)作为输入端。而每个像素点的灰度值（[0, 255]）则翻译成该神经元的输入脉冲数目。

![](images/92c7ad45a67b22e827931a5b997f703db48054b328cd418db4014b6c2662e804.jpg)  
图1.7：基于1T1M交叉阵列的忆阻突触矩阵与输入编码示意图[3]。忆阻器的电导值映射为神经网络中的权重，通过选中相应的1T1M结构并施加电压脉冲的方式来调节权重。

![](images/2ba2bb0fea28958f42a18cc7c10b79bab5fe3291ce7775676b786b30eb0d90d1.jpg)

# 二、输出编码

如图1.7右所示，源线（source line，SL）收集输出电流，然后经过一个非线性激活函数（activation function）处理。

思考题：对于上述人脸图像输入编码，除了用脉冲数目来编码像素点的灰度值，还有其它方案么？试着分析一下其它方案的优缺点，进而理解为什么作者使用了论文中的方案。

# 1.2.2 前向过程

图1.7右某根字线  $\mathrm{WL}_{\mathrm{x}}$  输入高电平，则该行全部晶体管都导通，于是列方向320根位线的输入电压脉冲顺利经过对应的忆阻器，总电流经源线  $\mathrm{SL}_{\mathrm{x}}$  汇合流出。以上电压经过忆阻器加权叠加为电流的过程，就是硬件层面执行神经网络的前向运算。它依赖两条物理原理：

1 欧姆定律(Omn's law) 德国物理学家欧姆于1826年提出，在同一电路中，通过某段导体的电流与此导体两端的电压成正比，与此导体的

电阻成反比。其标准式如下：

$$
I = \frac {U}{R} \tag {1.9}
$$

2 基尔霍夫定律(Kirchhoff's Law) 基尔霍夫电路定律描述了电路中电压和电流所遵循的基本规律，1845年由德国物理学家G.R.基尔霍夫提出，包括基尔霍夫电流定律（KCL）和基尔霍夫电压定律（KVL），是分析和计算复杂电路的基本方法。

基尔霍夫电流定律是电流连续性在集总参数电路上的具体体现，其物理背景是电荷守恒定律，它确定了任意节点处各支路电流之间的关系，具体表述如下：所有进入某节点的电流总和等于流出该节点的电流总和，或者说任意节点的电流代数和为零。其标准式如下：

$$
\sum_ {k = 1} ^ {n} i _ {k} = 0 \tag {1.10}
$$

其中  $i_{k}$  是第  $k$  个支路流入或者流出此节点的电流。

上述两式联合起来，即执行了神经网络的前向运算。

# 1.2.3 权重更新：写验证与写不验证

图1.7忆阻突触阵列的电导更新分为两种方式:

1 写验证(write with verify)  
2 写不验证(write without verify)

# 一、写验证算法的执行流程如图1.8所示：

首先，由字线与位线共同选中需要更新权重的忆阻突触单元。以图1.8下方为例，施加电压信号给  $\mathrm{WL}_1$  与  $\mathrm{BL}_2$  ，从而选中突触单元  $w_{12}$  。接下来，假定  $w_{12}$  需要增加  $\Delta w_{12}$  ，则对应的目标电阻值为  $R_{t} = (w_{12} + \Delta w_{12})^{-1}$  。权重更新系统每对突触  $w_{12}$  执行一次置态操作，紧接着读取该突触的电阻值  $R_0$  ，假如  $R_0$  大于目标值  $R_{t}$  ，说明还需要继续降低突触的电阻，这种情况下如果连续置态次数没有超过上限  $N$  ，则继续置态，而如

![](images/af4c50aa7e403fb20ef02316de696d3e7c5b26b9b48acd0542487293d3b20686.jpg)  
图1.8：写验证算法流程图与操作示意图[3]。  $\mathrm{WL}_1$  与  $\mathrm{BL}_2$  施加电压，选中突触单元  $w_{12}$  。首先进行读操作，  $\mathrm{WL}_1$  施加较大的电压，使晶体管导通，同时  $\mathrm{BL}_2$  加较小的电压，保证不会使忆阻器电导改变，通过  $\mathrm{SL}_1$  收集电流，根据欧姆定律得出  $w_{12}$  的电导值。之后进行写操作，  $\mathrm{WL}_1$  加较小的电压，起到限流的作用，同时  $\mathrm{BL}_2$  加大电压，对忆阻器进行一次置态操作。之后便是再一次读操作，并且验证是否达到目标电导值。

果超过了上限，突触器件电阻仍未降到目标以下，则说明器件出现了意外，此时终止对该器件的写操作；假如  $w_{12}$  在某轮置态操作后，读取电阻值小于目标值  $R_{t}$ ，说明置态成功，结束对它的编程操作。

可以看到，上述操作是不停地“写入”  $\rightarrow$  “读取”  $\rightarrow$  “验证”，这就是该流程“写验证”的命名由来。

而在具体操作上，如图1.8右下方所示，写验证的每一次执行是由一对读/写脉冲组成的：在“读”阶段，位线是低电平，而字线是高电平；而在“写”阶段，位线与字线的电平设置则反过来。这里的物理机制是：

1 “读”阶段字线的高电平是为了使晶体管处在低阻状态，因此位线施加的读电压基本都降落在忆阻器上，这样才能保证读出来的是忆阻器的电阻，而不会包含来自串连晶体管的显著误差。至于位线的低电平则是忆阻器“读”而不“写”的要求。  
2 “写”阶段字线的低电平是忆阻器置态时的限流(compliance current)要求。给定同样的置态电压脉冲，比较高的限流通常会导致忆阻器的电导变化比较大，超过我们要求的权重增加步长  $\Delta w_{0}$  。

总结上述“写验证”工作流程，可以看到，它是为了解决忆阻突触权重更新的非理想效应问题。假如每一个置态脉冲能够准确地提升突触权重  $\Delta w_{0}$ ，那么只需要连续提供  $N = [\Delta w_{12} / \Delta w_{0}]$  个置态脉冲即可。由于目前忆阻器电导调制的内禀随机性，基于忆阻器的仿生突触很难精确实现上述理想特性，因此需要复杂的“写验证”操作。

# 二、写不验证算法的执行流程如图1.9所示：

由图可见，“写不验证”算法比“写验证”算法大大简化，它实际上就是曼哈顿法则（公式1.8）的硬件版本。无论算出来的突触权重更新值是多少，该算法只关心值的正负，是正值则提供一个置态脉冲，反之则给一个重置脉冲。

看到这里，读者心里一个问题会油然而生：这么简单粗暴的处理其合理性何在呢？或者说它针对忆阻突触器件有什么特别好处呢？

首先，相比写验证方法，它大大简化了硬件电路设计以及操作控制。这一点毋庸赘述。

![](images/1a67301e150791c02f1676dc58242a119ada164359ed42d1ecfc91803d2abf98.jpg)  
图1.9：执行批量学习的写不验证算法流程图[3]。首先初始化网络的突触权重，之后依次输入九张图片，并根据梯度下降的链式法则计算突触权重的改变量。在九张图片的权重改变量全部计算完成之后，将九个改变量相加，根据曼哈顿法则，通过相加之后结果的符号决定最终权重改变的正负，并进行一次固定步长的置态操作。在这样一次训练完成之后，输入一张新的测试图片验证网络误差是否达到要求，来决定下一步继续训练或者结束训练。

其次，在阵列操作层面，两种算法一个根本区别是，写验证无法并行，而写不验证则可以高度并行。

从图1.8左下方电路可以看到，在阵列层面，突触权重更新操作要想并行，要么是同一根字线对应的不同位线单元并行，要么是同一根位线对应的不同字线单元并行。对于写验证方法，首先排除前者，原因是同一根字线对应的不同位线单元同时操作的话，这一行所有忆阻突触的电流是在同一根源线汇总的，这意味着各自的电流无法区分，因此各个忆阻突触的电阻就无从验证。

而假如是同一根位线对应的不同字线单元同步操作，写验证方法面临的最大问题是，各个忆阻突触写操作的循环次数并不相同，在实际操作中会出现有的已经编程完成，有的还远没达到期望值。这就失去了并行更新统一操作、简化控制电路的意义。

相反，对于写不验证方法，无论是同一根字线对应的不同位线单元，还是同一根位线对应的不同字线单元，均可并行编程。前者原因是写不验证不需要根据流经各个忆阻突触的电流测算器件的写入效果，因此不担心

电流在汇总到源线后无法区分。后者则是因为写不验证就是一步操作，不存在各个忆阻突触更新周期数不同的问题。

最后，对比写验证方法对突触权重较为准确的更新，写不验证方法是否真的大大降低了收敛速度？我们即将从实际训练效果展开分析。

# 三、两种算法的训练效果对比如图1.10所示：

![](images/26e3816b32077e3d209d6415a9d4ee6a06da0c0e12493fbf79248c8d5b6b058a.jpg)  
图 1.10: 写验证/不验证训练效果对比[3]。(a)写验证方法网络训练次数与收敛效果示意图。(b)写不验证方法网络训练次数与收敛效果示意图。(c)写验证/不验证在耗时、耗能以及准确率方面的对比。

![](images/1aca088ef7be2568ccd2d1b3531ee85c7547d3666c9ea2a01b7ec1fa6e55ee57.jpg)

![](images/8cfd145e0c8c8987d35c6175d0f80bec23d78175c46c97992d6707376d139cf9.jpg)

首先，对比左图和中图，神经网络要通过测试，采用写验证方法的最外层循环次数是显著小于写不验证方法的。这是不难理解的，每一次循环，前者对突触权重的更新比后者要准确得多，因此收敛要快得多。

但考虑到写验证方法的循环嵌套以后，实际训练的时间与能量消耗情况很可能完全不一样了。图1.10c对比了两种方法的耗时（latency）、耗能（energy）与结果准确度（accuracy），它似乎指出写验证方法更优越。然而，由于该工作没有对写不验证方法引入并行处理，后者的巨大优势完全没有反映出来。实际上，该工作者在后续系列工作中采用的是写不验证方法，他们将该方法进一步推广到多层神经网络，并命名为正负号反向传播（signed backpropagation，SBP）[4]。

# 1.2.4 忆阻突触器件：理想与现实

分析前述写验证方法可知，假如忆阻突触的电导能够在全同置态/重置脉冲序列下以  $\Delta w_{0}$  为单位，准确、稳定可重复地增加/减小，那么就不需

要验证操作和相关的复杂电路设计，而直接施加  $n = \left[\Delta w / \Delta w_{0}\right]$  个置态/重置脉冲即可（[]表示取整， $\Delta w$  是根据误差极小化计算出来的权重改变量）。

然而，理想很丰满，现实很骨感。前述工作制备的忆阻突触器件其模拟电导调制特性（analog weight update）如图1.11所示[3]。

![](images/6fab73f7fd652f6cd9c5b6bb2e628cd535c812872d07620b7b6a81efe6808cd3.jpg)

![](images/fa060d1cd802492a1734e3ab415fe88ba15dbf41eb271200bb5131734808f5d8.jpg)

![](images/f7458230099c93fced0577d83c88d4af8c4acf6001430b87ab8c3af653a2ffd6.jpg)

![](images/839dd32b41d28cbe3011b2084c71a17be78fc0f3250adb433674c9e6887f795f.jpg)

![](images/bf5672ea3347bada654dffa8292324ca47b3c59c56be93776ba7726871364e4a.jpg)  
图1.11：1T1M突触的模拟电导调制方差[3]。图中展示了四个突触器件在不同幅值的脉冲下进行置态和重置的结果，可以看出来不同器件电导调制特性差异明显，这种器件上的不一致性会对网络的训练效果产生一定影响。

![](images/e14ae22f0197d1b124939d13962a266b79b0f2fc60e5a477456b9e2cb3d84b4b.jpg)

![](images/0c50110e79ca3f10297fcd38ddea2a2db85fe8b5144c6ea4afa764d1e1a773bf.jpg)

![](images/642002c433f8f3c7d2018e7fc09ba9e163cd70f26e8283248114005e9250042b.jpg)

真实器件表现出非常显著的一致性问题，不仅是同一个器件的多次置态/重置操作电导调制方差（cycle-to-cycle variation，C2CV），还表现为不同器件的特性方差（device-to-device variation，D2DV）。这些一致性问题是由器件电导调制的内禀随机性导致的，参考本书第2章节对其相关的物理机制及应对策略讨论。

思考题：对比图1.10展示的神经网络训练效果，一个很有意思的问题是，在图1.11所示如此严重的器件性能方差下，训练仍然能够收敛，背后的物理机制是什么呢？

# 1.3 基于忆阻器差分对的突触阵列：三宫格识别

另一个基于忆阻突触阵列的单层神经网络监督学习代表作是美国加州大学Strukov教授团队于2015年发表的工作*[5]。本章节仍然按照忆阻神经网络设计的一般流程，逐项剖析讲解该工作，并重点分析该设计跟前述1T1M忆阻神经网络的不同之处及相关的设计思想、创新点。

# 1.3.1 带偏置项的输入编码

如图1.12左方所示，基于三宫格的九个像素点由九个输入神经元编码。注意这里引入了第十个输入神经元，也就是偏置项（bias term），它的特殊意义即将在后续讨论如何提升神经网络训练的收敛速度时凸显出来。

![](images/d6edf9eb01bc8cdfafe840f5c645daca8bf66f4fbf90753c6861c8c8740a8c5c.jpg)  
图1.12：基于三宫格的字母识别与神经网络输入编码[5]。  $3 \times 3$  分辨率的图片每个像素点被编码成高低电平作为网络的输入。同时加入了第三个输入偏置项，是为了平衡输入黑白像素点的数目，以使输出电流接近0，在此处双曲正切激活函数的斜率最大，因此神经网络的收敛速度会加快。

图1.12右方显示了包含10个输入神经元、3个输出神经元的全连接神经网络结构，该工作用到的激活函数是双曲正切函数  $f(I) = \tanh (I)$  。根据公式1.4，采用双曲正切激活函数的神经网络其收敛速度在  $I = 0$  处最大： $\max f^{\prime}(I) = f^{\prime}(0)$  。这意味着，给定了输入样本，我们要尽量通过输入编码设计使得对应的输出电流基本为0。

如图1.13中间所示，字母z、v和n用九个像素点编码，黑色和白色像素点的数目不平衡。因此，假如直接采用  $\pm V_{\mathrm{R}}$  来编码黑/白像素点，在初始权重随机分布的情况下，输出电流很难为0。而一旦引入了输入的偏置项，就可以通过偏置项来平衡黑白像素数目，从而加快了神经网络训练的收敛速度。

![](images/ea865617ea6542c0230c360ee711486b6b687682650206bb1246908a25064ce0.jpg)  
图1.13：基于忆阻器差分对的突触器件及读操作[5]。（a）基于忆阻突触阵列的差分对结构， $G^{+}$ 和 $G^{-}$ 共同组成一个突触权重。（b）读操作示意图，输入黑白像素编码成高低电平，通过施加读电压并收集突触电流的方式得到网络的输出。

# 1.3.2 负权重实现：差分对方案

不同于前述1T1M结构，该工作用一对忆阻器即差分对（differential pair)来构成一个突触[5,6]，如图1.13所示。  $I^{+}$ 电流对应的是充当被减数的忆阻器列，而  $I^{-}$ 则是减数忆阻器列。

# 1.3.3 阵列级权重更新方案

基于差分对的忆阻突触阵列写操作如图1.14所示。它的基本思想是：固定差分对中的减数忆阻器阻值，增大或减小被减数忆阻器的阻值。对应到图1.14右，即只更新每相邻两列忆阻器中的被减数这一列。而图1.14左指

出，该忆阻交叉阵列更新策略用的是曼哈顿法则： $\operatorname{sgn}[\Delta W]$ 。

![](images/9cef2a87a0388754a4e63af8cf453d4b3baa684a69592f167075649a42f1afab.jpg)  
图1.14：基于忆阻器差分对的突触器件及写操作[5]。图左表示计算得到的突触权重更新矩阵，权重的增减分别用  $+$  和  $-$  表示。当更新第一列权重时，先考虑突触权重需要增加的器件写入操作，如图右所示，对于  $G^{+}$  这一列，需要增加突触权重的器件在其左端施加  $-V_{\mathrm{W}}^{+} / 2$  ，否则为0；同时在其底端施加  $+V_{\mathrm{W}}^{+} / 2$  ，此时需要增加突触权重的被减数器件两端电压刚好是  $V_{W}$  ，于是对  $G^{+}$  器件执行了一次置态操作。而在本次操作中，需要减少突触权重的  $G^{+}$  忆阻器两端电压为  $+V_{\mathrm{W}}^{+} / 2$  ，没有达到置态阈值，因此不发生电导变化。

具体执行中，该工作使用了忆阻交叉阵列电导更新的一个常用技巧：把写电压  $V_{\mathrm{W}}^{(\pm)}$  设置为如下幅值：

$$
V _ {\mathrm {W}} ^ {(\pm)} > V _ {\mathrm {t h}} ^ {(\pm)} > V _ {\mathrm {W}} ^ {(\pm)} / 2 \tag {1.11}
$$

如图1.14右所示，首先选择更新被减数忆阻器需要被置态的那些器件，即图左第一列中标识为 + 的器件，对它们的一端（神经网络输入端）施加  $-V_{\mathrm{W}}^{+} / 2$  的电压，而未选中的接地；对另一端（神经网络输出端）施加  $V_{\mathrm{W}}^{+} / 2$  的电压。于是图左第一列显示需要增加电导的忆阻器单元两端电压达到了

$V_{\mathrm{W}}^{+}$ , 超过置态阈值  $V_{\mathrm{th}}^{+}$ ; 而图左第一列显示需要减小电导的忆阻器两端电压则是  $V_{\mathrm{W}}^{+} / 2$ , 未达到阈值  $V_{\mathrm{th}}^{+}$ 。以此类推突触权重需要减小的那些忆阻器电压操作。通过这种方式, 仅需两步即能更新图1.14右忆阻交叉阵列的一整列器件。

思考题：上述权重更新方案相当于固定减数而改变被减数以获得可正可负的相对电导值，你认为还有别的操作方式么？如果有，从器件层面分析它的优缺点各是什么？

# 1.3.4 训练结果与讨论

图1.15展示了基于差分对的突触阵列训练效果。

![](images/185e3cf3560071a41425838c796092fb2d9b469f29e57624e06a59b3451d0cbd.jpg)  
图 1.15: 三宫格识别问题的忆阻神经网络训练结果[5]。（a）识别错误率随训练次数增加而减小，以及初始化网络权重与最终网络收敛后权重对比。（b）分别代表三种字母的输出神经元的响应随训练次数的变化。

![](images/8151fb02f9ac7af4b3b5162b038014d94f25e4481954465074b326531b10c7ed.jpg)

图1.15b显示，代表字母  $z$  、v和n的三个输出神经元，它们对z（黑线），v（红线）和n（蓝线）输入的响应随着训练次数的增多而区分度越来越显著，在大约15次后达到饱和。

# 2 深度神经网络

# 2.1 算法原理：误差的反向传播

对于一个如图2.1所示的多层神经网络，我们首先定义它在前向运算中涉及到的各个物理量：第  $k - 1$  层的输出为  $x_{k - 1}$ ；经过第  $k$  层的突触阵列  $W_{k}$  后，得到第  $k$  层的输入  $s_k$ ；再经过第  $k$  层的激活函数  $f$ ，得到第  $k$  层的输出  $x_{k}$ 。

![](images/533ca15ff6604143387786df692568144cc2d4c777519e1390ebcf860b50d2c3.jpg)  
图2.1：多层神经网络的前向和反向传播。前向传播：第  $k - 1$  层神经元的输出为  $x_{k - 1}$ ，经过第  $k$  层神经元的突触阵列  $W_{k}$ ，成为第  $k$  层神经元的输入  $s_k$ ，再经过本层神经元的激活函数  $f_{k}$ ，得到第  $k$  层的输出  $x_{k}$ 。反向传播：输出层  $N$  处实际输出对照期望值产生误差  $\delta_N$ ，该误差逆向经过突触阵列往回传播，在第  $k$  层神经元的误差为  $\delta_{k}$ 。

图2.1中的前向过程用如下公式描述：

$$
s _ {k} = x _ {k - 1} \cdot W _ {k} + b _ {k} \tag {2.1}
$$

$$
x _ {k} = f _ {k} \left(s _ {k}\right)
$$

其中， $b_{k}$  是第  $k$  层输入时的偏置项。显然上式第一步是矢量矩阵相

乘(VMM)，而第二步是激活函数处理。

接下来，我们仍然采用梯度下降算法来计算各层突触权重的更新值：

$$
\begin{array}{l} \Delta W _ {k} = - \eta \frac {\partial E}{\partial W _ {k}} \\ = - \eta \frac {\partial E}{\partial s _ {k}} \frac {\partial s _ {k}}{\partial W _ {k}} \\ = - \eta \frac {\partial E}{\partial s _ {k}} x _ {k - 1} \\ = - \eta \frac {\partial E}{\partial x _ {k}} \frac {\partial x _ {k}}{\partial s _ {k}} x _ {k - 1} \\ = - \eta \frac {\partial E}{\partial x _ {k}} f _ {k} ^ {\prime} \left(s _ {k}\right) x _ {k - 1} \tag {2.2} \\ = - \eta \frac {\partial E}{\partial s _ {k + 1}} \frac {\partial s _ {k + 1}}{\partial x _ {k}} f _ {k} ^ {\prime} (s _ {k}) x _ {k - 1} \\ = - \eta \frac {\partial E}{\partial s _ {k + 1}} W _ {k + 1} f _ {k} ^ {\prime} \left(s _ {k}\right) x _ {k - 1} \\ = - \eta \frac {\partial E}{\partial s _ {k + 2}} W _ {k + 2} f _ {k + 1} ^ {\prime} (s _ {k + 1}) W _ {k + 1} f _ {k} ^ {\prime} (s _ {k}) x _ {k - 1} \\ = - \eta \frac {\partial E}{\partial s _ {N}} \prod_ {i = N} ^ {k + 1} W _ {i} f _ {i - 1} ^ {\prime} (s _ {i - 1}) x _ {k - 1} \\ \end{array}
$$

上述推导过程可称为链式法则，它从当前层开始，终止于输出层  $N$ 。对照图2.1，上述推导的物理含义是很清楚的，假如第  $k$  层神经元的突触权重发生了变化  $\Delta W_{k}$ ，它是如何通过神经网络逐层前向传播，从而改变了最后输出以及误差的： $\Delta W_{k} \rightarrow \Delta s_{k} \rightarrow \Delta x_{k} \rightarrow \Delta s_{k+1} \rightarrow \Delta x_{k+1} \rightarrow \dots \rightarrow \Delta s_{N} \rightarrow \Delta x_{N} \rightarrow \Delta E$ 。

在实际使用中，假如直接根据公式2.2的最后表达式计算各层突触权重的变化量，会有一系列问题。首先可以看到，越靠近输入层，其突触权重更新表达式越冗长，以微软公司研制的用于图像识别的52层卷积神经网络为例，该计算公式将变得极其复杂；其次，对于不同层的突触权重更新表达式  $\Delta w_{k}$  与  $\Delta w_{k + 1}$ ，很显然有大量的中间量被重复计算，导致计算极其低效且代价巨大。

有鉴于此，研究人员引入了一个新的中间量，即第  $k$  层神经元的反向传播误差  $\delta_{k}$  ：

$$
\delta_ {k} = \frac {\partial E}{\partial s _ {k}} \tag {2.3}
$$

于是公式2.2迅速简化为：

$$
\Delta W _ {k} = - \eta \delta_ {k} \cdot x _ {k - 1} ^ {T} \tag {2.4}
$$

这里需要注意  $\Delta W_{k}$  是一个矩阵，而  $\delta_{k}$  和  $x_{k-1}$  是两个列向量，故而需要将  $x_{k-1}$  转置。换句话说，权重更新矩阵是输入列向量与反向传播误差行向量两者相乘的结果，这正是后续章节用忆阻交叉阵列一步实现整个突触矩阵更新的关键。

公式2.2还指出，第  $k$  层神经元的反向传播误差  $\delta_{k}$  本身可以通过递推来计算：

$$
\delta_ {k} = \operatorname {D i a g} \left(f _ {k} ^ {\prime} \left(s _ {k}\right)\right) W _ {k + 1} \cdot \delta_ {k + 1} \tag {2.5}
$$

其中  $\operatorname{Diag}$  表示将列向量  $f_{k}^{\prime}(s_{k})$  转为对角化的矩阵。这里要特别注意，误差反向传播，实际上也是一个矢量矩阵相乘运算，只不过是逆向经过突触矩阵。这意味着，反向传播的本层误差也能用忆阻交叉阵列与后一层误差相乘而一步获得。

而输出层的反向传播误差  $\delta_N$  则可以从定义获得：

$$
\begin{array}{l} \delta_ {N} = \frac {\partial E}{\partial s _ {N}} \\ = \frac {\partial E}{\partial x _ {N}} \frac {\partial x _ {N}}{\partial s _ {N}} \tag {2.6} \\ = (y - y ^ {d}) \operatorname {D i a g} \left(f _ {N} ^ {\prime} (s _ {N})\right) \\ \end{array}
$$

其中， $y^{(d)} = x_N^{(d)}$  是神经网络第N层（即输出层）的输出矢量（期望值）。

综合公式2.4、2.5和2.6，可以得到多层神经网络监督学习的权重更新过程：

1. 首先根据定义式2.6计算输出层的反向传播误差  $\delta_{N}$ , 与前一层的输出  $x_{N-1}$  相乘, 即得到输出层的突触权重更新  $\Delta W_{N}$ ;  
2 根据反向传播误差的递推表达式2.5，由输出层的反向传播误差  $\delta_{N}$  计算紧邻输出层的倒数第一隐藏层反向传播误差  $\delta_{N-1}$ ，与倒数第二隐藏层的输出  $x_{N-2}$  相乘，得到倒数第一隐藏层的突触权

重更新  $\Delta W_{N - 1}$

3 以此类推，从神经网络输出层到输入层，逆向逐层求得对应的突触权重更新  $\Delta W_{k}$  。

上述求解过程就是反向传播的命名由来。

# 2.2 反向传播的忆阻交叉阵列实现

对照图2.2显示的神经网络第  $k$  层突触阵列，我们发现通过列向量  $\delta_{k}$  与行向量  $x_{k-1}^{T}$  相乘能够一步完成公式2.4定义的权重更新矩阵，而不是逐个计算、更新突触矩阵的每一个元素。

![](images/49f5b4c96771ba5c70f768e977d5ff84c447ac98497d74b3f6d6cb780f20d853.jpg)  
图2.2：基于忆阻交叉阵列的反向传播示意图。根据误差反向传播的突触权重更新公式2.4，第  $k$  层神经元的突触矩阵其更新  $\delta_W$  是一个列向量  $x_{k-1}$  与一个行向量  $\delta_k$  相乘的结果。其中列向量  $x_{k-1}$  是输入前向传播到当前层的结果，而行向量  $\delta_k$  则是实际输出与期望值的误差反向传播到当前层的结果。

然而仔细推敲相应的硬件实现方案，会发现有一系列的设计问题需要解决：

1. 第  $k - 1$  层输出  $x_{k - 1}$  是电压形式，因此它能够直接用于突触权重的更改，但  $\delta_{k}$  不是一个电压量纲的物理量。那么如何将  $\delta_{k}$  编码成可以修改突触权重的写电压？

2 假定该多层神经网络用到的激活函数  $f$  是sigmoid函数，那么  $x_{k}$  始终为正，它的大小可以通过若干个全同电压写脉冲来编码；然而  $\delta_{k}$  作为误差是可正可负的，又如何处理负的  $\delta_{k}$ ？  
3 假定已经将反向传播误差  $\delta_{k}$  编码为突触权重的写电压，那么它跟  $x_{k-1}^{T}$  相乘的效果在硬件上又如何实现呢？注意两个电压相乘的结果是电压的平方，从量纲上它就无法直接用于忆阻突触器件的电导调制。

对于前两个问题，我们假定图2.2中的忆阻突触器件具有比较理想的模拟权重更新(analog weight update)特性，即其电导可以在全同的置态/重置电压脉冲序列下产生等幅度的上升/下降变化： $\delta V_{\mathrm{SET}} \rightarrow \Delta W_{+}$ ； $\delta V_{\mathrm{RESET}} \rightarrow -\Delta W_{-}$ 。那么对形如下式的  $\delta_{k}$  可编码为相应的写脉冲数量：

$$
\delta_ {k} = \left[ \begin{array}{c} + a _ {1} \\ - a _ {2} \\ \vdots \\ + a _ {l - 1} \\ - a _ {l} \end{array} \right] \Rightarrow \left[ \begin{array}{c} \left[ \frac {a _ {1}}{\Delta w _ {+}} \right] \delta V _ {\text {S E T}} \\ \left[ \frac {a _ {2}}{\Delta w _ {-}} \right] \delta V _ {\text {R E S E T}} \\ \vdots \\ \left[ \frac {a _ {l - 1}}{\Delta w _ {+}} \right] \delta V _ {\text {S E T}} \\ \left[ \frac {a _ {l}}{\Delta w _ {-}} \right] \delta V _ {\text {R E S E T}} \end{array} \right] \tag {2.7}
$$

上式中  $a_{i} \geq 0$ , 而  $[ ]$  表示取整操作。

对于忆阻突触器件，通常  $\delta V_{\mathrm{SET}}$  与  $\delta V_{\mathrm{RESET}}$  不仅方向相反，脉冲幅度也不一样。因此需要将上述编码进一步拆分：

$$
\delta_ {k} ^ {+} = \left[ \begin{array}{c} {\left[ \frac {a _ {1}}{\Delta w _ {+}} \right] \delta V _ {\mathrm {S E T}}} \\ 0 \\ \vdots \\ {\left[ \frac {a _ {l - 1}}{\Delta w _ {+}} \right] \delta V _ {\mathrm {S E T}}} \\ 0 \end{array} \right], \quad \delta_ {k} ^ {-} = \left[ \begin{array}{c} 0 \\ {\left[ \frac {a _ {2}}{\Delta w _ {-}} \right] \delta V _ {\mathrm {R E S E T}}} \\ \vdots \\ 0 \\ {\left[ \frac {a _ {l}}{\Delta w _ {-}} \right] \delta V _ {\mathrm {R E S E T}}} \end{array} \right] \tag {2.8}
$$

相应的，  $x_{k - 1} = [b_1,b_2,\dots b_{l' - 1},b_{l'}]^T$  编码如下：

$$
x _ {k - 1} ^ {+} = \left[ \begin{array}{c} {\left[ \frac {b _ {1}}{\Delta w _ {+}} \right]} \\ {\left[ \frac {b _ {2}}{\Delta w _ {+}} \right]} \\ {\vdots} \\ {\left[ \frac {b _ {l ^ {\prime} - 1}}{\Delta w _ {+}} \right]} \\ {\left[ \frac {b _ {l ^ {\prime}}}{\Delta w _ {+}} \right]} \end{array} \right] \delta V _ {\mathrm {S E T}}, x _ {k - 1} ^ {-} = \left[ \begin{array}{c} {\left[ \frac {b _ {1}}{\Delta w _ {-}} \right]} \\ {\left[ \frac {b _ {2}}{\Delta w _ {-}} \right]} \\ {\vdots} \\ {\left[ \frac {b _ {l ^ {\prime} - 1}}{\Delta w _ {-}} \right]} \\ {\left[ \frac {b _ {l ^ {\prime}}}{\Delta w _ {-}} \right]} \end{array} \right] \delta V _ {\mathrm {R E S E T}} (2. 9)
$$

$x_{k - 1}^{+}$  与  $\delta_k^+$  配对，而  $x_{k - 1}^{-}$  与  $\delta_k^-$  配对，如图2.3所示。换言之，在忆阻突触矩阵的权重更新中，实际上是需要两步的，第一步更新那些权重需要增加的  $\{\delta_k^+, x_{k - 1}^+T\}$ ，第二步更新余下需要减少的  $\{\delta_k^-, x_{k - 1}^-T\}$ 。

![](images/06d9db212ac53a977b9345791f49a87ca1f76b4c00d19c0cf145eec1c8b8384c.jpg)  
图2.3：基于忆阻交叉阵列的正负权重更新设计[7]。横坐标是前向因子  $x_{i}$  而纵坐标是反向传播的误差  $\delta_{j}$ ，由红变蓝的色度条代表它们的乘积大小，即突触权重更新量  $\Delta W_{ij}$  。注意  $\delta_{j} \geq 0$  由上平面表示，而  $\delta_{j} < 0$  由下平面表示。图中特意将权重更新量的等高线画出来，以便下一步的离散化处理。

# 思考题：

1 为什么不将  $x_{k - 1}$  和  $\delta_{k}$  编码成如下形式：

$$
x _ {k - 1} = \left[ \begin{array}{c} {\left[ \frac {b _ {1}}{\Delta w _ {+}} \right] \delta V _ {\mathrm {S E T}}} \\ {\left[ \frac {b _ {2}}{\Delta w _ {+}} \right] \delta V _ {\mathrm {R E S E T}}} \\ {\vdots} \\ {\left[ \frac {b _ {l ^ {\prime} - 1}}{\Delta w _ {+}} \right] \delta V _ {\mathrm {S E T}}} \\ {\left[ \frac {b _ {l ^ {\prime}}}{\Delta w _ {+}} \right] \delta V _ {\mathrm {R E S E T}}} \end{array} \right], \quad \delta_ {k} = \left[ \begin{array}{c} {\left[ \frac {a _ {1}}{\Delta w _ {+}} \right] \delta V _ {\mathrm {S E T}}} \\ {\left[ \frac {a _ {2}}{\Delta w _ {-}} \right] \delta V _ {\mathrm {R E S E T}}} \\ {\vdots} \\ {\left[ \frac {a _ {l - 1}}{\Delta w _ {+}} \right] \delta V _ {\mathrm {S E T}}} \\ {\left[ \frac {a _ {l}}{\Delta w _ {-}} \right] \delta V _ {\mathrm {R E S E T}}} \end{array} \right] \tag {2.10}
$$

这样不就只需要一步更新了吗？

2 假如  $x_{i-1}$  是可正可负的，例如是由双曲正切型激活函数  $f(x) = \tanh(x)$  产生，那么上述方案又该如何调整呢？

接下来，我们考虑第三个问题即两个电压脉冲相乘的解决方案。如图2.4所示，Burr等人提出一种巧妙的设计[7]。

首先，将图2.3所示的  $\delta_{k}^{\pm}x_{k - 1}^{\pm T}$  乘积等高线做离散化处理，得到图2.4所示由若干方块区域组成的近似。而自变量  $\delta_{k}^{\pm}$  和  $x_{k - 1}^{\pm}$  本身也被离散化，用相应的脉冲数量来表示。

接下来，我们以  $\delta_k^+ x_{k-1}^{+T}$  为例，分析它是如何设计电压相乘效果的。注意  $\delta_k^+$  和  $x_{k-1}^+$  幅值均被设计成半写脉冲高度  $V_{\mathrm{pulse}} = \delta V_{\mathrm{SET}} / 2$ ，也就是说，如图2.4右方所示，当且仅当  $\delta_k^+$  和  $x_{k-1}^+$  的脉冲对准时，才能对忆阻突触产生写效果。

然后Burr等人有意将  $\delta_{k}^{\pm}$  和  $x_{k - 1}^{T}$  离散化后对应的脉冲序列设计成图2.4右方所示的分布。我们以  $x_{i}^{+} = 3V_{\mathrm{SET}}$  、  $\delta_{k}^{+} = 2V_{\mathrm{SET}}$  为例，由于前述的半脉冲幅值对准效果，它们在时间上输入后，产生的就是2个完整的置态电压脉冲  $\delta V_{\mathrm{SET}}$  ，正是图2.4左方相应区域所需要的结果。读者可自行验证图2.4左方各个区域要求的电导调制阶数（从0到4）均可由右方所示的对应脉冲组合完成。

![](images/26b36944f1761aef642bfb2df76fc919340785650b0185c2e9e0103fa957a638.jpg)  
图2.4：基于忆阻交叉阵列的反向传播设计[7]。左图：横坐标是前向因子  $x_{i}$ ，而纵坐标是反向传播的误差  $\delta_{j}$ ，且按其正负分为上下两个平面表示。横坐标与纵坐标的乘积对应突触权重更新量  $\Delta W_{ij}$  。注意这里将  $\Delta W_{ij}$  按等高线覆盖范围离散化了，因此获得每个方格对应的整数个权重更新单位  $\Delta_0$  。右图：为实现方格中数目的权重更新单位，前向因子  $x_{i}$  和反向传播因子  $\delta_{j}$  各自的波形设计。注意这里再次用到了半写脉冲幅值方法，即脉冲幅值为  $V_{\mathrm{W}} / 2$  与  $-V_{\mathrm{W}} / 2$ ，它们的差值  $V_{\mathrm{W}} > V_{\mathrm{th}}$ ，但它们自身  $V_{\mathrm{W}} / 2 < V_{\mathrm{th}}$  。

# 2.3 忆阻突触的非理想效应与对策

# 2.3.1 忆阻突触的非理想特性

图2.5总结了当前用非易失存储器*模拟突触权重调制时常见的各种非理想效应[7]:

![](images/6857aeca4b277fbdfab95694f1d6b9cd73da60cbea2461311baf432898b584a3.jpg)  
图 2.5: 非易失存储器仿生突触时的各种非理想效应[7]。横坐标是连续施加的置态/重置脉冲, 纵坐标是器件的电导。

1. 器件无法置态 dead devices: 器件初始处在高阻态, 但施加的写电压无法将其电阻态。以氧化铪/氧化钽复合层忆阻器为例, 这通常是工艺制备过程中, 大面积沉积的功能材料在衬底表面不够均匀导致的。  
2 器件无法重置(devices stuck-on)：器件被置到低阻态以后，无法重置到高阻态。以氧化铪忆阻器为例，通过置态脉冲形成的导电丝很牢固，重置脉冲很难通过电迁移效应将导电丝中的离子反向撤回。  
3 电导调制非线性(nonlinearity): 在全同置态/重置脉冲序列作用下,器件电导增加/减小的步长不再是固定的。如图2.5所示, 在置态过程中, 忆阻器电导出现饱和效应; 在重置过程中, 电导出现陡降现象。

在后续章节中，本书将通过若干忆阻材料与器件实例讲解上述非线性现象的物理机制。

4 电导增减非对称性(asymmetry)：置态脉冲引起的电导增加量  $\Delta G_{0}^{+}$ 与重置脉冲引起的减小量  $\Delta G_{0}^{-}$ 幅值差异很大，反映在图2.5中电导上升曲线与下降曲线的斜率差别很大，两者的非对称性较高。  
5 随机性(stochasticity): 器件电导在置态/重置脉冲下的改变并不是预期值, 甚至有时候测得实际电导的增加/减小与预期截然相反。这种电导调制随机性是当前不同材料机理忆阻器面临的一个普遍问题。以前述章节的  $\mathrm{TaO}_{\mathrm{x}}$  忆阻器为例, 氧空位在电场作用下的迁移有较大的随机性, 这种随机性可能由热运动导致, 也可能由于迁移路径上的局域结构差异导致。在忆阻突触器件层面, 随机性导致如下两种性能问题:

5.1 多次操作离散度（cycle-to-cycle variation，C2CV）：对同一个器件，不同的写操作周期获得的长时程增强/减弱特性曲线不重合，有相当的离散度。  
5.2 不同器件操作离散度（device-to-device variation，D2D V）：对不同器件，它们的长时程增强/减弱特性曲线不重合，有相当的离散度。

# 2.3.2 基于非易失存储器差分对的人工突触及操作设计

如图2.6所示，Burr等人在深度神经网络的硬件实现层面提出利用非易失存储器件差分对配合选通管来构成突触[7]。注意这里的关键词有两个，一个是差分对，另一个是选通管。

忆阻器差分对突触在前述章节初步讨论过，通过这种结构可获得可正可负的突触权重，而这对神经网络的训练效率至关重要。Burr等人进一步发展了该结构对应的突触更新操作方法，目的是克服忆阻突触器件中一个常见的非理想特性：忆阻器电导增加或减小的突变性导致的增减非对称性。我们将在随后的更新操作中详细讨论这个方法以及它引入的新问题。

而选通管的作用如图2.6右上角所示，它可以简单地理解为一种特殊的二极管，具有单向导通特性。但跟二极管不同之处在于，选通管一旦

![](images/5e4eb55c1e34590b03b77cf36450a50e1141b6df996991725cd2d9b0435a12fe.jpg)  
图2.6：基于非易失存储器差分对的仿生突触及阵列[7]。如何将左图两层相邻神经元  $\{N_{1},\dots ,N_{n}\}$  和  $\{M_1,\dots ,M_m\}$  的突触连接映射到右图的忆阻器交叉阵列。注意首先是用两列忆阻器单元的差分来表示一个输出神经元的突触，其次，每个忆阻器单元包含了一个选通管器件。

达到阈值电压  $V_{\mathrm{th}}$  而导通，两端的电压降落（也叫保持电压  $V_{\mathrm{hold}}$ ）通常在0.1V左右，远低于二极管导通状态的维持电压0.7V，如图2.7所示。这一特点有利于图2.6中的输入电压基本降落在与选通管串连的目标忆阻器上，由此在操作层面输入电压矢量、突触电导矩阵相乘没有显著偏差，在神经网络层面就是前向过程得以正确执行。前述章节已详细讲解一种基于阈值转换型忆阻器的选通管实例，以及相应的1S1M结构对阵列层面潜行电流效应的有效抑制。

![](images/7f0e329209068180f443030d8c70cae513f60becf1ff9d63278890fdc4a8799d.jpg)  
图2.7：选通管的直流伏安扫描特性[8]。基于钛钨电极/硫化铜/硒化锗/铂电极（TiW/CuS/GeSe/Pt）的导电桥型阈值转换器件实测结果。注意它在正向电压达到阈值电压  $V_{\mathrm{th}}$  后开启，即从高阻态跳变为低阻态，然后只要两端电压高于保持电压  $V_{\mathrm{hold}}$  ，它仍保持为低阻态，而  $V_{\mathrm{hold}}$  远小于  $V_{\mathrm{th}}$  。

# 一、前向操作

神经网络的前向操作，也就是突触矩阵与该层输入矢量的乘加操作，如图2.8所示。

![](images/ddcc7a585d345c9bcd40c1dbe8c3e6d4872d956fb6b4ecdeee4325f4d2611ab9.jpg)  
图2.8：基于非易失存储器差分对的突触阵列前向操作[7]。

$$
\begin{array}{l} I _ {j} = I _ {j} ^ {+} - I _ {j} ^ {-} \\ = \sum_ {i} x _ {i} G _ {i j} ^ {+} - \sum_ {i} x _ {i} G _ {i j} ^ {-} \tag {2.11} \\ = \sum_ {i} x _ {i} \left(G _ {i j} ^ {+} - G _ {i j} ^ {-}\right) \\ \end{array}
$$

# 二、更新操作

以图2.5所示的实际忆阻突触权重调制特性为例，器件电导在重置脉冲作用下有一个陡降(abrupt decrease)。换言之，突触器件的模拟权重调制特性仅在增强（ $\Delta w > 0$ ）时能够提供足够精度的权重值，而当神经网络训练要求比较精确的权重减弱（ $\Delta w < 0$ ）时，器件特性达不到要求。

针对这一难题，Suri和Burr等人相继提出和发展了一种新的忆阻差分对操作方式[7, 9]。它的数学原理很简单，对一个差分对，假如想增大它俩代表的值，就增大被减数，反之则增大减数。对应到硬件层面操作是，当突触权重需要增加时，就对  $G_{ij}^{+}$  忆阻器置态；反之则对  $G_{ij}^{-}$  置态。因此，

这个方案只利用了置态连续性比较理想的忆阻器特性，而避开了陡变的重置操作。

![](images/c7a6a9f9945918f3e92f49781d1bcb28071c9f01879705d62493d529c3a36a31.jpg)  
图2.9：基于非易失存储器差分对的突触更新操作[7]。左上图与左下图分别是充当差分对被减数  $G^{+}$  和减数  $G^{-}$  的器件电导更新特性，注意灰色斜线是理想行为，而饱和曲线是实际行为。右图是差分对的电导相减，即对应的突触权重。假设差分对两个器件的初始状态是图中的④，由于器件的电导只能增大不能减小，那么一轮更新操作后，如左上图所示，被减数电导  $G^{+}$  几乎不变，而减数  $G^{-}$  则会增大到左下图的状态⑧，因此它们的差值即突触权重如右图所示是变小了：④  $\rightarrow$  ⑧。同理，假如俩器件初始状态分别为左上图和左下图的⑥，那么一轮更新操作后，它们差值代表的权重演化为右图所示的⑨  $\rightarrow$  ⑩。也就是说，无论差分对的初始电导情况如何，它们的演化趋势是向右图菱形的右方尤其是顶点汇集。

然而如图2.9所示，上述操作方式的最大问题是，此处的忆阻器类似中国象棋里的过河卒子，只能前进不能后退，一旦到达底线就动弹不得。以充当减数的忆阻器件为例，一旦它的电导被调制到最大值，对应的差分对突触权重就无法再减小了，从神经网络学习层面，它就无法支持训练的继续了。

一种补救措施是周期性的刷新，如图2.10插图所示。当两个忆阻器的电导  $G^{+}$  和  $G^{-}$  在训练中逐渐饱和，就插入刷新操作：首先将两个忆阻器的电导都重置回高阻态，然后根据  $(G^{+} - G^{-})$  的正负将  $G^{+}$  或者  $G^{-}$  的电导置态到  $|G^{+} - G^{-}|$  。这样在保证差分对代表的突触权重不变的情况下，  $G^{+}$  和  $G^{-}$  的绝对值都大大减小了，意味着它们的电导又可以在训练中被增大了。

![](images/1db78bb4ee4eb65ae0e0a232eb46ac986627cd517afe2ff1883ed56f7878df5b.jpg)  
图2.10: 差分对突触刷新操作频率对训练效果的影响[7]。横坐标表示在（对差分对忆阻器电导）刷新操作之间训练的手写数字集图片数目，纵坐标是大规模神经网络仿真结果，带方块的红线和带圆形的蓝线分别是对训练集和测试集的准确率。插图是充当被减数和减数的忆阻器件电导  $G^{+}$  和  $G^{-}$  演化示意图，不同箭头分别代表两个器件的电导演化以及刷新操作导致的变化。

然而，上述刷新方案只能说“看上去很美”。首先，神经网络每更新若干次权重，就必须刷新一次。换句话说，两次刷新操作之间能容忍的突触更新次数是很有限的。在实际应用中就会有如图2.10所示的问题：假如采用在线学习法则，即每输入一个样本都更新一次神经网络的突触权重，那么即使对于手写数字识别标准测试集（modified national institute of standard and technology，MNIST）这种相对而言很小的测试集，仍然会出现样本数大于100，准确率就大幅下降。

其次，上述刷新方案在重置后将充当被减数或者减数的忆阻器电导  $G^{+}$  或  $G^{-}$  置态到  $\left|G^{+} - G^{-}\right|$  的操作，所需的电路硬件及操作流程跟前述章节的“写验证”方案是完全一样的，因此面临的实际问题也是一样的：硬件开销大、时间代价高且很难并行。

思考题：你认为两次刷新操作之间能容忍的突触更新次数主要由器件的哪项性能指标决定？

# 三、读写电路

神经网络的训练是由反复循环的前向、更新操作构成的，从硬件层面意味着需要对图2.6中突触器件的多轮读、写操作，而读和写的电压设计、电路模块是很不一样的，因此Burr等人给出了如图2.11所示的读写电路设计。

# 2.3.3 实验与仿真结果讨论

图2.5列出了忆阻突触器件的多种非理想因子，那么在神经网路层面它们对训练效率的影响各自有多大呢？换句话说，哪些因子对训练成功的破坏作用最大，而哪些因子又能够在网络层面被容错呢？

Burr等人基于他们制备的大规模相变差分对突触阵列（约165,000个突触器件），针对手写数字识别标准测试集，构建了一个包含528（图像分辨率  $22 \times 24$ ）个输入神经元、250个第一隐藏层神经元、125个第二隐藏层神经元、10个输出层神经元的多层全连接神经网络，通过实验与仿真，得出器件非理想因子对神经网络训练效果影响的定量评估，如图2.12所示：

图中蓝线表示使用的是高度理想的忆阻突触器件，即器件的电导调制在全同置态/重置脉冲下是完全线性的，且电导态没有上下限(unbounded)，

![](images/8c965e5bba642fd8ff8886bbec8fbc12edda5865714d645d90dcfb290d77f944.jpg)  
图 2.11: 基于相变器件差分对的突触读写电路[7]。首先通过字线选中阵列的某行, 而从目标位线输入读/写电流  $I_{\mathrm{D}}$  给选中的单元。注意读、写用到不同的外部电路。

![](images/524d683e8ec84e87ada38779f3b54b96427e66b369bdbf918767bca899eb06c0.jpg)  
图2.12：非易失存储器差分对仿生突触的非理想效应对网络训练影响[7]。横坐标是训练次数，纵坐标是大规模神经网络仿真获得的测试集准确率。图中不同颜色曲线代表突触器件权重更新的不同特性。其中，蓝线代表高线性度且增长无上限（unbounded）；红线代表高线性度、可增可减（bidirectional）但权重存在上下限（bounded）；绿线代表高线性度、只能线性增加（uni-directional）且权重存在上下限；粉线代表非线性、只能线性增加且权重存在上下限。右上角插图是上述四种情况下的突触权重更新示意图，即长时程增强/减弱曲线。左下角插图是差分对器件的电导演化情况。

如插图中的  $G(N_{\mathrm{pulse}})$  所示；而红线代表对理想器件引入电导态的上下限(bounded)；绿线则进一步引入器件电导调制的单向性(uni-directional)，即高度线性的电导调制行为仅存在于置态过程中；粉红线更进一步引入了电导调制的非线性(nonlinearity)。

图2.12展示的神经网络识别准确率随训练次数的演化指出：

1 仅仅引入电导态的上下限，会引起神经网络约  $10\%$  的性能下降。  
2 引入忆阻器电导调制的单向性，会引起神经网络性能  $40\%$  左右的剧烈下降。  
3 引入忆阻器电导调制的非线性因子，会引起神经网络性能约  $20\%$  的显著下降。

思考题：如何理解上述各项非理想因子对神经网络性能的不同影响？

图2.12的插图给出了忆阻差分对电导随训练次数的演化情况。可以看到，在训练开始的时候，器件电导是随机的，因此大部分器件的电导分布在菱形的左方两臂上；随着训练次数增多，如前图2.9所述，差分对的电导倾向于向菱形的右方两臂移动，最终不再能按要求调制。例如，处在菱形右上臂附近的差分对，其权重将无法正向增大；而处在菱形右下臂的，其电导将无法负向增大。

# 3 本章小结

# 1 神经网络监督学习的算法要点

1.1 学习对象是带标签的数据(labeled data)。  
1.2 单层神经网络：只包含输入与输出层；N层神经网络：包含输入、输出与  $(N - 1)$  个隐藏层。定义神经网络为多少层，是不包括输入层的，原因是输入层是没有突触的，不属于可塑的，因此不计入有效的神经网络层数。

1.3 梯度下降：定义了神经网络实际输出与期望值之间的误差后，误差成为神经网络突触权重的函数，然后利用梯度下降法极小化误差，由此求解出突触权重的改变量应该是多少。

# 2忆阻突触的核心优势

狭义上的忆阻器可以理解为以阻变存储器(RRAM)为代表的二端器件，其电导在外加电压作用下能够发生非易失的、可逆的转变。而市面上主流的闪存(flash memory)即浮栅晶体管(floating-gate transistor)或电荷俘获存储器(charge trapping memory)，原则上也满足忆阻器的广义定义，即电导可非易失地、可逆地调制。

有若干研究工作探讨了用NAND闪存（NAND flash memory）或NOR闪存（NOR flash memory）来实现神经形态计算，尤其是近年来迅猛发展的3维堆叠NAND存储器(3D NAND)，因其超高密度、超大容量的优势，有可能支持超大规模的神经网络实现而受到重点关注[10]。

然而，闪存器件用来做神经形态器件最大的问题是擦写速度太慢。这个太慢不仅表现为单个浮栅/电荷俘获器件的擦写速度，还反映在NAND是块擦除。因此，基于闪存的神经形态计算目前主要是面向“云端训练 + 边缘计算”架构，而闪存充当边缘计算的执行端。以汽车智能驾驶为例，每一辆装载了某款类脑智能驾驶芯片的汽车都是一个终端，它把采集到的数据传送给云端的服务器，服务器据此训练好神经网络以后，将神经网络的参数发送回车载芯片，更新芯片上的神经网络。可以看到，这里“边缘计算”支撑的是实时驾驶，因此它要求响应是实时的，而“训练”和“更新”操作则可以在终端不执行驾驶任务的空闲时间进行。

相比之下，忆阻器模拟突触时的电导调制时间是纳秒量级，且忆阻交叉阵列结构允许任一单元的随机访问[11]。因此，基于忆阻器的类脑计算芯片能够支持实时的片上训练，它带来训练效率的革命性提升，更适合性能要求较高的应用场合。

# 3 反向传播与忆阻交叉阵列实现

3.1 对于多层神经网络，它每一层神经元的全部突触构成一个矩阵，对应的权重更新矩阵可以写成一个列矢量与一个行矢量相乘的形式。其中，列矢量是输入矢量前向传播到当前层神经元的结果，而行矢量是输出与期望值的误差矢量反向传播到当前层的结果。  
3.2 从硬件角度，这样一个形式特别适合用忆阻交叉阵列来实现。首先，输入前向传播对忆阻交叉阵列是一个读过程，矢量矩阵相乘可以通过忆阻交叉阵列一步完成。  
3.3 其次，误差反向传播对忆阻交叉阵列也是一个读过程，只不过是将阵列原先的输入与输出端倒置。  
3.4 第三，在获得（输入前向传播的）列矢量和（误差反向传播的）行矢量后，对突触权重矩阵的更新，原则上也可以通过巧妙的写电压脉冲编码一步完成。

# 4忆阻突触权重更新的问题和挑战

狭义上的忆阻器即非易失存储器，顾名思义，原本是用来做非易失的存储器件。非易失存储器从二值存储发展到多值存储，对应的正是忆阻突触的可调制电导态数目，数目越多，则模拟值效果越好。

然而，从前非易失存储器用作多值存储遇到的问题，在新的忆阻突触器件领域仍然存在，同样也深刻地影响了器件性能。

首先是多值电导的可得问题。从模拟突触的角度，要求在器件的最高阻态与最低阻态之间存在若干个中间值的亚稳态，且这些中间态的数目越多越好。而从能量的角度，中间态的数目越多，它们彼此的能量差别就会越小，态与态之间发生互相转化、跃迁的概率就越高，即保持特性越差。换句话说，忆阻突触器件的两项关键指标，即由电导态数目(multi-levels)标识的模拟性和由保持时间(retention)标识的非易失性之间，存在根本的矛盾。

其次是随机性问题。忆阻器的电导调制，无论是依靠导电丝的形成/断裂，还是晶态/非晶态的转换，抑或是铁电畴的极化翻转，这些过程从微观物理机制上就是有很大随机性的。用于模拟突触时，这

种随机性会导致很严重的问题，即实际电导改变值与训练预期值之间存在不可忽视的偏差。

本书将在后续章节详细讨论基于不同材料、物理机制的多种忆阻突触器件。

# 参考文献

[1] Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding deep learning requires rethinking generalization, 2017.  
[2] Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding deep learning (still) requires rethinking generalization. _Commun. ACM_, 64(3):107-115, February 2021.  
[3] Peng Yao, Huaqiang Wu, Bin Gao, Sukru Burc Eryilmaz, Xueyao Huang, Wenqiang Zhang, Qingtian Zhang, Ning Deng, Luping Shi, H-S Philip Wong, et al. Face classification using electronic synapses. Nature Communications, 8:15199, 2017.  
[4] Qingtian Zhang, Huaqiang Wu, Peng Yao, Wenqiang Zhang, Bin Gao, Ning Deng, and He Qian. Sign backpropagation: An on-chip learning algorithm for analog rram neuromorphic computing systems. Neural Networks, 108:217-223, 2018.  
[5] Mirko Prezioso, Farnood Merrikh-Bayat, BD Hoskins, Gina C Adam, Konstantin K Likharev, and Dmitri B Strukov. Training and operation of an integrated neuromorphic network based on metal-oxide memristors. Nature, 521(7550):61, 2015.  
[6] M. Prezioso, F. Merrikh-Bayat, B. Chakrabarti, and D. Strukov. RRAM-based hardware implementations of artificial neural networks: progress update and challenges ahead. In Ferechteh H. Teherani, David C. Look,

and David J. Rogers, editors, Oxide-based Materials and Devices VII, volume 9749, pages 127 - 135. International Society for Optics and Photonics, SPIE, 2016.  
[7] G. W. Burr, R. M. Shelby, C. di Nolfo, J. W. Jang, R. S. Shenoy, P. Narayanan, K. Virwani, E. U. Giacometti, B. Kurdi, and H. Hwang. Experimental demonstration and tolerancing of a large-scale neural network (165,000 synapses), using phase-change memory as the synaptic weight element. In 2014 IEEE International Electron Devices Meeting, pages 29.5.1–29.5.4, 2014.  
[8] 王宽. 基于阈值开关忆阻器随机性的概率类脑计算研究. 博士学位论文, 华中科技大学, May 2022.  
[9] M. Suri, O. Bichler, D. Querlioz, O. Cueto, L. Perniola, V. Sousa, D. Vuillaume, C. Gamrat, and B. DeSalvo. Phase change memory as synapse for ultra-dense neuromorphic systems: Application to complex visual pattern extraction. In 2011 International Electron Devices Meeting, pages 4.4.1–4.4.4, 2011.  
[10] Sung-Tae Lee and Jong-Ho Lee. Neuromorphic computing using nand flash memory architecture with pulse width modulation scheme. Frontiers in Neuroscience, 14:945, 2020.  
[11] Sung Hyun Jo, Ting Chang, Idongesit Ebong, Bhavitavya B Bhadviya, Pinaki Mazumder, and Wei Lu. Nanoscale memristor device as synapse in neuromorphic systems. Nano Letters, 10(4):1297-1301, 2010.