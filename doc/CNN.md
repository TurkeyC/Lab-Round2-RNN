# 卷积神经网络

# 何毓辉

# he.yuhui.ime@gmail.com

# 2022年11月1日

# 目录

# 1 基本原理 3

1.1 特征提取：第一层卷积核 3  
1.2 特征提取：池化 4  
1.3 特征提取：后续层卷积核 5  
1.4 分类：拍平与全连接 6

# 2 2维忆阻阵列实现 6

2.1 负权重的电路实现 9  
2.2 激活函数的电路实现 11  
2.3 平均池化的电路实现 13  
2.4 3维卷积核运算的电路实现 13  
2.5 权重更新的电路实现 14  
2.6 卷积的并行实现 17  
2.7 忆阻突触阵列的非理想效应 18  
2.8 芯片级体系结构 20

# 3 3维忆阻阵列实现 21

3.1 设计理念 21  
3.2 设计与实现实例 22

4 本章小结 28

参考文献 28

前述章节讲解的神经网络实例虽然执行的算法或者训练方式各不相同，但从结构上都是全连接型（fully-connected）。以“”为例，对结构最简单的单层神经网络，其训练获得的突触权重图谱（synapse maps）代表什么可以直观地显示出来。然而，像“”展示的多层神经网络，除了紧随输入层的第一隐藏层其突触权重图谱有比较清晰的物理解释，越靠近输出层，神经元对前面若干层运算的综合程度越高，因此突触权重含义的直观性、可解释性越差。换句话说，多层全连接神经网络有显著的“黑箱子”（black box）特性：即使训练成功了，结果也很难诠释。这对一些安全性、可理解性要求很高的应用场合，显然是不可接受的。

![](images/034dd80e117df6ad54d220960d59146ee12c731a02d347b2b6c8f39021e7a79f.jpg)  
图0.1：卷积神经网络示意图。卷积神经网络作为一种多层神经网络，从结构上可以分为“特征提取”和“分类”两大块。以手写数字图片识别为例，输入是一张  $28 \times 28$  像素的手写数字图片，第一次卷积操作是用6个  $2 \times 2$  的卷积核分别与原始图片卷积，通过边缘补0，获得6张  $28 \times 28$  的特征图，即图中的C1层；接下来执行  $2 \times 2$  的池化操作，获得6张  $14 \times 14$  的特征图，即图中的S2层；第二次卷积操作是用16个  $5 \times 5 \times 6$  的卷积核分别与S2层卷积，注意这里的卷积核是三维的，可以看作是6张  $5 \times 5$  的二维卷积核合成一个三维卷积核，其中每张  $5 \times 5$  二维分量与S2层的一张特征图对应卷积，得到6个卷积结果再求和，即图中的C3层；紧接着池化为16张  $5 \times 5$  的特征图，即图中的S4层。经过上述特征提取后，将C3层的全部神经元拍平，以全连接方式依次经过含120个神经元的F5层、84个神经元的F6层、10个神经元的输出层，实现不同手写数字的分类。

本章讲解一种特殊结构的神经网络，即卷积神经网络。如图0.1所示，

相比全连接型，它的结构设计是比较清晰的：首先划分为“特征提取”（feature extraction）与“分类”（classification）两大部分；而“特征提取”是采取类似堆积木的做法，首先从输入样本中提取简单的小特征，然后把小特征组合成更复杂的大特征。这里的小特征、大特征对应的是越来越复杂的卷积核，用卷积核在样本上或者样本经过前一层卷积处理得到的特征图。（feature map）上“扫描”，寻找符合卷积核特征的区域。由于卷积核是通过训练得到的，这意味着小特征、大特征并不是像通常图像处理算法那样事先指定了滤波器种类如方向梯度直方图（histogram of oriented gradients, HOG），而是根据训练样本集自身的特点，由神经网络自我摸索出来的。

原则上，卷积核以及样本通过卷积核后生成的特征图是可以可视化（visualize）的[1-4]，因此卷积神经网络可以有较好的可解释性。并且，不同于全连接型神经网络，同一个卷积核会“扫过”输入样本的各个子区域，相当于突触连接被复用（multiplex）了，因此节省了大量的突触。这既大幅度降低了硬件成本，也极大地减少了训练参数。

由于上述优势，卷积神经网络是目前应用落地最成功的一类神经网络，尤其是在图像识别等领域。本章首先讲解卷积神经网络的一般工作原理，然后讲述基于二维忆阻交叉阵列的实现方案，最后介绍最新的三维堆叠忆阻阵列实现方案。

# 1 基本原理

# 1.1 特征提取：第一层卷积核

第一层卷积核也叫做感受野（receptive field），每一个卷积核代表一种特征。这种特征可以是各种具体的形状，也可以是某种滤波器（filter），例如图1.1中的两个卷积核分别提取原始图像的水平、垂直方向梯度信息，综合起来就是对原始图像的边缘检测（edge detection）。

从图0.1中可以看到，当用卷积核逐行、逐列扫描原始图像时，其实就是在原始图像上找跟卷积核图案最相似的局部图案。所得的C1特征图每一个元素大小就反映了原始图像对应的局部区域跟卷积核图案相似度。这就是基于卷积操作的特征提取。

![](images/dfe8fc1310957bf620c352a6d47397e4aac2530a4e77b727fa10d2d79854c225.jpg)  
图1.1：用于边缘检测的卷积核[5]。图左是来自视频某帧的原始图像，图中两个  $3 \times 3$  的卷积核f1和f2分别是用来检测水平和垂直方向的图像变化，f1,out和f2,out分别是经过f1和f2处理后的图像，图最右是两者的叠加效果  $\sqrt{(\mathrm{f}1,\mathrm{out})^2 + (\mathrm{f}2,\mathrm{out})^2}$  。

# 1.2 特征提取：池化

池化操作的目的是降低特征图的尺度，以减小计算代价。从操作上可分为最大池化（maximum pooling）与平均池化（average pooling）。

以图0.1为例，经过第一次卷积操作后，得到C1层的6张  $28 \times 28$  像素特征图。采用  $2 \times 2$  的最大/平均池化操作，即把  $28 \times 28$  原始图像按照  $2 \times 2$  的块大小分成  $14 \times 14$  份，每一份取该  $2 \times 2$  模块4个元素的最大/平均值，即得到S2层的池化结果。

分析上述操作，可以看到池化的作用有两个：第一，降低计算的硬件与时间代价；第二，防止过拟合（overfitting）。第一点是显而易见的，我们这里重点解释第二点。

以人脸识别为例，人的“呼”和“吸”会导致脸部轮廓出现微小的差别，现在假设喂给卷积神经网络的训练样本是“呼气”时的人脸照片，而测试样本是“吸气”时的。假如没有池化处理，那么卷积核训练得到的是“呼气”时的精确轮廓线，当测试样本是“吸气”的轮廓线时，它跟卷积核的运算结果就会低于期望值，换句话说，对“吸气”的人脸测试样本就识别不出来。究其原因，是因为在训练阶段对样本细节提取要求过高而出现了过拟合现象。

相比之下，池化处理就是模糊化，只要轮廓线出现在池化区域内就可

以了。

# 1.3 特征提取：后续层卷积核

由图0.1可知，从第二层卷积运算开始，卷积核变成三维了。这是卷积神经网络如何把小特征拼成大特征的关键步骤。

![](images/5a2722880770aec3294ce79d1b5d1bbb2abf5a92e27a5c1595eb9c1b4e226622.jpg)

![](images/e26feba198c2736f4d8a6c5e346697d4e2b89719b6434865838844fbc86aaf53.jpg)  
图1.2: 3维卷积核应用效果示例。现有两个手写数字图像输入“8”和“9”，第一次卷积运算使用两个卷积核，能够从原始图像中分别提取出“○”和“/”这两个简单图案。对于“8”，它可以仅依赖第一次卷积提取的“○”图案，将上下两个“○”拼接在一起，就得到了“8”；对于“9”，它需要将第一次卷积的“○”和“/”两个图案拼在一起，表现在图中就是需要将第一层的两张特征图不同部分拼接在一起，因此是将两个二维卷积核分别与对应的特征图卷积，结果再相加。这两个二维卷积核拼在一起就是三维卷积核，厚度即前一层特征图的数量，也就是前一次卷积运算的卷积核数目。

以图1.2为例，通过两层卷积来识别数字“8”和“9”。我们首先可以

粗略把“8”和“9”分别拆分为两个“○”，一个“○”和一个“/”的组合。于是第一层卷积设置两个2维的卷积核，通过训练，它们分别能够识别出原始图像中的“○”和“/”。如图1.2上方所示，第一层卷积以后得到的两个特征图指出了“○”和“/”在原始图像“8”中是否存在，以及如果存在，位置在哪里。

对于“8”来说，接下来的第二层卷积只需要如图中所示的一个卷积核，它作用在第一层卷积得到的第一张特征图上，就可以把两个不同位置的“○”拼在一起，于是图案“8”及其位置就被识别出来了。

然而，对于“9”来说，需要把第一层卷积得到的第一张特征图的“○”和第二张特征图的“/”拼在一起，才能得到“9”，因此需要如图1.2下方所示的三维卷积核。

# 1.4 分类：拍平与全连接

由上述讨论可知，经过多次卷积与池化以后，神经网络的特征提取部分将能够从输入图形中提取出较为复杂的特征，接下来通过如图0.1所示的神经网络分类部分即拍平(flatten)与全连接，最终实现对原始输入图像的识别。

拍平操作，顾名思义是将最后一次池化得到的若干张特征图全部展开成一维的向量。原则上，该一维向量的每一个元素代表了训练样本一个较复杂的特征，由相应的神经元来表征。而接下来的多层全连接则是执行分类操作。

# 2 2维忆阻阵列实现

通过前述章节的讨论，我们知道忆阻交叉阵列最擅长执行的是矢量矩阵乘法vector matrix multiplication)，因此当我们考虑基于忆阻交叉阵列的卷积神经网络执行方案，马上会遇到如下问题：

• 2维和3维的卷积核如何用忆阻交叉阵列实现，或者说卷积运算如何用矢量矩阵乘法来实现？  
- 如何利用忆阻交叉阵列高效地执行卷积运算？

以2维卷积核在原始图像上的一系列平移、卷积操作为例，这些卷积运算本质上是互相独立的，只是需要对准的原始图像区域不同，那么，能否采取某种方式并行实现这些卷积运算？另外，同一层卷积的不同卷积核运算也是互相独立的，能否也在硬件层面并行执行？

上述两个问题是忆阻卷积神经网络设计的核心问题，而其它问题，例如突触更新操作如何实现等，跟前述章节讨论的全连接神经网络是共通的。

图2.1给出了卷积核如何映射到忆阻交叉阵列的方案[6]：对于  $K \times K \times C$  维度的三维卷积核，将它拍平成一维向量，然后写入到忆阻交叉阵列的某一列中；同时将原始图像或特征图的待卷积部分也拍平成一维输入电压矢量。通过上述设计，以矢量点乘方式实现了卷积运算。

接下来，假设本层卷积有  $N$  个卷积核，那么就调用忆阻交叉阵列的  $N$  列来对应写入，于是以矢量矩阵乘法形式，实现了  $N$  个卷积核对同一个输入矢量的并行卷积运算。

本节以美国代顿大学Yakopcic研究组的近期工作为例[7, 8]，系统讲解基于二维忆阻交叉阵列的卷积神经网络实现方案。

我们首先分析Yakopcic等人的研究思路：以2维忆阻交叉阵列为核心，如何搭建完整的电路系统来实现卷积神经网络？循着卷积神经网络的前向与更新操作过程，可以把问题拆解如下：

# 1 前向操作：

- 输入如何编码？  
- 负的突触权重如何实现？  
- 第1层卷积的2维卷积核如何映射到忆阻交叉阵列？  
- 池化操作如何用忆阻交叉阵列实现？  
- 激活函数如何用硬件电路模拟？  
- 第2层及后续卷积运算的3维卷积核如何映射到忆阻交叉阵列？  
- 拍平操作如何用忆阻交叉阵列实现？

# 2 更新操作：

![](images/89692dd3033f0808326e5a0813621a7dcb82d4370fd3ad8bdd9d21ac28f158f3.jpg)  
图2.1：基于2维忆阻交叉阵列的卷积运算示意图[6]。（a）图显示，前一次运算获得的特征图有  $C$  张，每张的尺寸是  $H \times W$  ，它们构成本次卷积运算的输入。而本次卷积运算有  $N$  个卷积核，尺寸为  $K \times K \times C$  。首先将原始特征图待卷积的部分，即图左上角用红、蓝、绿、白色标记的  $C$  个  $K \times K$  区域，拍平成1维向量，而每个元素的大小用电压幅值编码，得到  $M = K \times K \times C$  个输入电压，即  $\{V_{1}, V_{2}, \dots, V_{M}\}$  。接下来，将每一个卷积核也拍平成一维向量，而每个元素的大小用忆阻器的电导  $g_{mn}$  编码，进而写入到  $M \times N$  维的忆阻交叉阵列某一列，即  $\{g_{1,n}, g_{2,n}, \dots, g_{M,n}\}$  。当输入电压向量经过图中的忆阻交叉阵列，根据欧姆定律和基尔霍夫定律，获得一行输出电流  $\{I_{1}, I_{2}, \dots, I_{N}\}$ ，这个过程对应的就是  $N$  个三维卷积核对原始图案同一区域的并行卷积预算。

![](images/b0f85bc91ad93fa803d3a622baeb44d6abccf3d556f02bc532a15b2d36469108.jpg)

- 如何将目标权重（电导）与实际获得权重（电导）的比较，“翻译”成可测量的电流或电压比较？  
- 如何将上述比较结果转换为置态/重置的写电压？

# 3 器件非理想效应的影响：

- 低精度（ $\leq 4$  比特）的实际忆阻器件如何仿真高精度（ $\geq 8$  比特）的突触权重？  
- 忆阻突触的模拟权重更新非线性度、非对称性等，如何在操作中克服它们对神经网络运算的不利影响？

上述问题有些是用忆阻交叉阵列实现神经网络的普适问题(universal issues)，有些是卷积神经网络特有的问题，接下来我们讲解Yakopcic研究组针对这些问题的若干创新解决方案[7, 8]。

我们以图2.2所示的卷积神经网络为例，讨论它的忆阻阵列电路实现[7,8]。该卷积运算处理的是像素分辨率为  $28 \times 28$  的MNIST图片，第一层卷积使用6个  $5 \times 5$  的卷积核，得到6张  $24 \times 24$  的特征图；接下来采取  $2 \times 2$  的平均池化算法，且步长为2；第二层卷积使用12个  $5 \times 5 \times 6$  的卷积核，得到12张  $8 \times 8$  的特征图；第二次池化仍采用步长为2、大小为  $2 \times 2$  的平均操作；然后拍平对应192个次外层神经元，信号以全连接方式传输给输出层的10个神经元。

# 2.1 负权重的电路实现

图2.1展示了通过将2维/3维卷积核拍平为1维数组，可以用忆阻交叉阵列的1行/列实现1个卷积核。然而在实际应用中有一个问题是，神经网络突触的权重可以是负的，而忆阻电导不能是负的，因此需要考虑如何用忆阻器实现可正负的突触。

以公式2.1所示卷积核为例：

$$
k _ {\mathrm {e x}} = \left[ \begin{array}{c c c} 0. 1 & - 0. 2 & 0. 3 \\ - 0. 4 & 0. 5 & - 0. 6 \\ 0. 7 & - 0. 8 & 0. 9 \end{array} \right] \tag {2.1}
$$

![](images/9f4bf844e214fe50df1cf8e24327338fa7c8592afc2c1986cea7b4b2bde1637b.jpg)  
图2.2：使用忆阻电路实现的卷积神经网络示例[7,8]。针对  $28 \times 28$  像素的手写数字图像输入，该卷积神经网络第一次卷积用了6个  $5 \times 5$  尺寸的卷积核，得到6张  $24 \times 24$  尺度的特征图，进一步用  $2 \times 2$  池化处理，将特征图压缩至  $12 \times 12$  尺寸；第二次卷积用了12个  $5 \times 5 \times 6$  的三维卷积核，得到12张  $8 \times 8$  尺寸的特征图，接下来用  $2 \times 2$  池化处理，获得12张  $4 \times 4$  的特征图。上述“特征提取”（feature extraction）部分结果拍平后，得到196个神经元，接下来依次经过两次全连接层处理，得到代表10个手写字体的10个输出，即“分类”（classification）部分。

卷积运算表达式为：  $x_{11}\cdot 0.9 + x_{12}\cdot (-0.6) + x_{13}\cdot 0.3 + x_{21}\cdot (-0.8) +$ $x_{22}\cdot 0.5 + x_{23}\cdot (-0.2) + x_{31}\cdot 0.7 + x_{32}\cdot (-0.4) + x_{33}\cdot 0.1$

前述章节我们讨论过差分对(differential pair)方案，这里我们介绍Yakopcic提出的一个类似方案：

$$
\hat {x} _ {\mathrm {e x p}} ^ {+} = \left[ \begin{array}{l} x _ {1 1} \\ x _ {1 2} \\ x _ {1 3} \\ x _ {2 1} \\ x _ {2 2} \\ x _ {2 3} \\ x _ {3 1} \\ x _ {3 2} \\ x _ {3 3} \end{array} \right], \hat {x} _ {\mathrm {e x p}} ^ {-} = \left[ \begin{array}{l} - x _ {1 1} \\ - x _ {1 2} \\ - x _ {1 3} \\ - x _ {2 1} \\ - x _ {2 2} \\ - x _ {2 3} \\ - x _ {3 1} \\ - x _ {3 2} \\ - x _ {3 3} \end{array} \right], k _ {\mathrm {e x p}} ^ {+} = \left[ \begin{array}{l} 0. 9 \\ 0 \\ 0. 3 \\ 0 \\ 0. 5 \\ 0 \\ 0. 7 \\ 0 \\ 0. 1 \end{array} \right], k _ {\mathrm {e x p}} ^ {-} = \left[ \begin{array}{l} 0 \\ 0. 6 \\ 0 \\ 0. 8 \\ 0 \\ 0. 2 \\ 0 \\ 0. 4 \\ 0 \end{array} \right] \tag {2.2}
$$

将  $k^{+}$  和  $k^{-}$  如图2.3所示写入忆阻阵列的某一行，同时将  $\hat{x}^{+}$  和  $\hat{x}^{-}$  如图输入，从而实现了该卷积核对应的卷积运算：

$$
\nu = \sum_ {i} ^ {N} x _ {i} \sigma_ {i j} ^ {+} + \sum_ {i} ^ {N} (- x _ {i}) \sigma_ {i j} ^ {-} \tag {2.3}
$$

另外，要注意设计的两个细节问题：一个是如何将抽象的权重转换为忆阻突触的电导，这里需要考虑真实器件电导的上下限  $\sigma_{\mathrm{max / min}}$  ：

$$
\sigma^ {+} = \frac {\sigma_ {\operatorname* {m a x}} - \sigma_ {\operatorname* {m i n}}}{\operatorname* {m a x} \left| k _ {\mathrm {e x}} \right|} k _ {\exp} ^ {+} + \sigma_ {\min } \tag {2.4}
$$

$$
\sigma^ {-} = \frac {\sigma_ {\max} - \sigma_ {\min}}{\max  | k _ {\mathrm {e x}} |} k _ {\exp} ^ {-} + \sigma_ {\min }
$$

另一个是图中引入了偏置项输入  $x_{\beta}$  和权重  $\sigma_{\beta}$ , 原因前述章节已解释过。

# 2.2 激活函数的电路实现

图2.3左下角展示了以运算放大器为核心的输出电路模块，经过简单计算可以得知，在运放的线性工作区有如下关系：

$$
y _ {j} ^ {-} = - (\nu + x _ {\beta} \sigma_ {\beta}) \cdot M _ {g} \tag {2.5}
$$

$$
y _ {j} ^ {+} = - y _ {j} ^ {-}
$$

![](images/5cbeae6f38cb62a46236fd3d86531d1642426220388928ae481a7c66d1b737a7.jpg)  
图2.3：卷积核的二维忆阻交叉阵列实现[7,8]。如公式2.2所示，图中  $\sigma_{ij}^{+}$ 忆阻阵列的电导用来实现突触的正权重（  $w_{ij}\geq 0$  )，而负权重元素对应的电导被设置为0；  $\sigma_{ij}^{-}$  阵列的电导用来实现突触的负权重（  $w_{ij} < 0$  )，具体而言是映射  $w_{ij}$  的相反数，而正权重元素对应的电导被设置为0。相应的，输入向量  $\{x_{1},x_{2},\dots ,x_{N}\}$  取反后，分别从  $\sigma_{ij}^{+}$  与  $\sigma_{ij}^{-}$  阵列输入。注意另外引入了偏置项  $x_{\beta}\cdot \sigma_{\beta}$  。上述乘加运算结果输入给下方的运算放大器，利用负载电阻  $M_{g}$  、  $R_{f}$  近似实现激活函数 sigmoid。

如图2.4所示，这个输出电路模块是用上述表达式近似了sigmoid激活函数  $y = (1 + \exp (-\nu))^{-1}$ 。

这里的核心设计思想是，通过合理选取电路中的偏置项  $x_{\beta} \cdot \sigma_{\beta}$  、运放负载电阻  $M_{g}$ ，在激活函数输入0点附近，不仅运放函数值和sigmoid函数值相等，它们的一阶导数也相等；而在输入正负无穷大的两个极端，运放的输出饱和值也与sigmoid函数值一致。我们在前述章节讲过，通过设计偏置项，我们将模拟神经网络神经元的输入统计平均值尽可能设置在0点附近，以此获得较好的收敛速度，以及在多层神经网络中避免梯度消失。因此，图2.3和2.4的设计能够较好地用运放近似神经网络中的sigmoid激活函数。

![](images/494730c57f9ec8f3b0920c59c49e64bf2d38e022e3df8d17f39b7bf75d2882a1.jpg)  
图2.4：激活函数的运放实现[7,8]。图中虚线是sigmoid函数，实线是采取图2.3运算放大器电路得到的输入-输出函数曲线，是对sigmoid的近似。

# 2.3 平均池化的电路实现

平均池化也可以看做是用如下卷积核的一次卷积操作：

$$
k _ {e x} = \frac {1}{4} \left[ \begin{array}{l l} 1 & 1 \\ 1 & 1 \end{array} \right] \tag {2.6}
$$

图2.5展示了  $2 \times 2$  平均池化电路设计：

# 2.4 3维卷积核运算的电路实现

从图2.2可以看到，经过第一次卷积与池化操作以后，会得到6张  $12 \times 12$  的特征图。从卷积神经网络原理我们知道，这意味着下一次卷积核的

![](images/c2b704e4eb6c57de0c3007ccaf2880155de6ffc1ce844880f9f65cd3c7ef84cf.jpg)  
图2.5：平均池化的电路实现[7,8]。平均池化仍然采用忆阻阵列来做池化的核函数，只是相比卷积核要简单很多，每个忆阻器的电导值设置为相同即可。

第3维尺寸必须是6，因此第二次卷积操作的卷积核尺寸为  $5 \times 5 \times 6$  。将该3维卷积核拍平，计入负权重效应，并与6张  $12 \times 12$  特征图逐个元素对齐，就是如图2.6所示的忆阻交叉阵列电路。

最后，全部卷积和池化操作结束以后，我们得到若干张特征图，将其拍平为1维矢量，通过全连接传递给最后输出。此处电路实现与前述章节讲述的多层感知机完全一致，不赘述。

# 2.5 权重更新的电路实现

从设计角度，权重更新电路的要点有两个，第一是如何选中要写入电导值的忆阻器单元，第二是如何将选中的忆阻器电导值调制出需要的变化。

第一个问题，如图2.7上方所示，对于目标忆阻器，在位线施加读/写电压  $x_{t}$ ，而其它忆阻器的位线施加0电平，因此字线的输出电流完全由目标忆阻器贡献，保证了读出阻抗是目标忆阻器的。

第二个问题，我们分三种情况讨论输出  $y_{j}^{-}$ ：

![](images/40aaea481278da12676810fc8ce99ebd05225426220918a4e08ee6dd78fb624e.jpg)  
图2.6：3维卷积核的电路实现[7,8]。与图2.3展示的二维卷积核实现大体类似，只是此处是将三维卷积核拍平为1维的向量，然后写入忆阻交叉阵列对应的列中。

![](images/308890171e073b884dc9c111f3c0d0b00a220dca2eebba3fb2857c60033c0685.jpg)  
图2.7：卷积核权重更新的电路实现[7,8]。对于选中的目标忆阻器  $M_{t}$ ，从位线输入写电压  $X_{t}$ ，而对其它未选中的忆阻器，从位线输入0电压。这样保证字线端的输出电流完全由目标忆阻器  $M_{t}$  贡献。图右下方是决定  $X_{t}$  为置态还是重置电压、或者已经写完成的数模混合电路。其基本原理是，根据目标忆阻器的期望阻值  $M_{t}$ ，计算出期望电压  $\tau = -V_{\mathrm{READ}} \cdot \frac{M_g}{M_t}$ （注意  $V_{\mathrm{READ}}$  是施加在目标忆阻器上的读电压），进一步考虑误差容限  $\alpha$  得到期望电压的上下限  $V_{A1 / A2} = \tau \pm \alpha$ ，将计算结果通过数模转换电路（D-to-A）变成模拟值形式的电压  $V_{A1 / A2}$ ，分别施加到右下方的两个运放，而实际输出电压  $y_{j}^{-}$  输入到这两个运放的另一端。当  $y_{j}^{-} > \tau + \alpha$  时，与门被激活，于是对忆阻器施加重置脉冲，增加其阻值，使得下一次读出的  $y_{j}^{-}$  减小；当  $y_{j}^{-} < \tau - \alpha$  时，与非门被激活，于是对忆阻器施加置态脉冲，减小其阻值，使得下一次读出的  $y_{j}^{-}$  增大；当  $\tau - \alpha < y_{j}^{-} < \tau + \alpha$  时，异或门被激活，不再对忆阻器施加写电压，写操作结束。

1  $y_{j}^{-} > \tau + \alpha$  ：图2.7下方以  $y_{j}$  为输入之一的两个运放都输出高电平，因此图右下方的与门、异或门、与非门分别输出高电平、低电平、低电平。在这种情况下，重置电压被激活，将目标忆阻器  $M_{t}$  的阻值提升。  
2  $y_{j}^{-} < \tau -\alpha$  ：上述以  $y_{j}$  为输入之一的两个运放均输出低电平，后续的与门、异或门、与非门分别输出低电平、低电平、高电平。这种情况下，置态电压被激活，将目标忆阻器  $M_{t}$  的阻值降低。  
3  $\tau - \alpha < y_{j}^{-} < \tau + \alpha$  : 图中以  $y_{j}$  为输入之一的两个运放分别输出高电平、低电平, 后续的与门、异或门、与非门分别输出低电平、高电平、高电平。这种情况下, 异或门输出有高的优先级, 因此没有置态/重置脉冲, 目标忆阻器  $M_{t}$  阻值不再变化。

综合上述讨论，当且仅当输出电压  $y_{j}^{-}$  被调制到  $[ \tau - \alpha, \tau + \alpha ]$  区间，忆阻器阻值不再被调制。换句话说， $\tau$  是根据目标忆阻器  $M_{t}$  的期望阻值换算出来的期望电压，而  $\alpha$  代表的是一定程度的误差容限。

# 2.6 卷积的并行实现

对于“卷积核在原始图像上的移动”，前述章节给出的方案是将原始图像拆为卷积核大小的若干个，然后滚动输入。例如按照卷积核的像素尺寸  $3 \times 3$  ，将  $4 \times 4$  像素的原始图像拆为4个(步长为  $1 \times 1$  )，然后顺序输入这4个一维矢量给忆阻交叉阵列，依次得到4个值，构建相应的  $2 \times 2$  特征图。

以上方法在实际图像处理中将付出较大的时间代价。另一方面，我们知道，求取特征图各个元素值的运算是互相独立的，因此原则上是可以并行的。有鉴于此，Yakopcic等人提出了一种以较大硬件代价来换取高并行度的方案[8]。它的基本思想是，将完整的输入拍平为一个很大的1维向量，据此设计忆阻突触阵列的大小。形象地说，这个方案不再是将输入削足适履来适应卷积核大小，而是将卷积核扩充来适应完整的输入大小。

$$
k _ {\exp} ^ {+} = \left[ \begin{array}{l l l l} 0. 9 & 0 & 0 & 0 \\ 0 & 0. 9 & 0 & 0 \\ 0. 3 & 0 & 0 & 0 \\ 0 & 0. 3 & 0 & 0 \\ 0 & 0 & 0. 9 & 0 \\ 0. 5 & 0 & 0 & 0. 9 \\ 0 & 0. 5 & 0. 3 & 0 \\ 0 & 0 & 0 & 0. 3 \\ 0. 7 & 0 & 0 & 0 \\ 0 & 0. 7 & 0. 5 & 0 \\ 0. 1 & 0 & 0 & 0. 5 \\ 0 & 0. 1 & 0 & 0 \\ 0 & 0 & 0. 7 & 0 \\ 0 & 0 & 0 & 0. 7 \\ 0 & 0 & 0. 1 & 0 \\ 0 & 0 & 0 & 0. 1 \end{array} \right], k _ {\exp} ^ {-} = \left[ \begin{array}{l l l l} 0 & 0 & 0 & 0 \\ 0. 6 & 0 & 0 & 0 \\ 0 & 0. 6 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ 0. 8 & 0 & 0 & 0 \\ 0 & 0. 8 & 0. 6 & 0 \\ 0. 2 & 0 & 0 & 0. 6 \\ 0 & 0. 2 & 0 & 0 \\ 0 & 0 & 0. 8 & 0 \\ 0. 4 & 0 & 0 & 0. 8 \\ 0 & 0. 4 & 0. 2 & 0 \\ 0 & 0 & 0 & 0. 2 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0. 4 & 0 \\ 0 & 0 & 0 & 0. 4 \\ 0 & 0 & 0 & 0 \end{array} \right] \tag {2.7}
$$

如公式2.7所示，原始  $4 \times 4$  图像完全展开后是一个  $16 \times 1$  的列向量，那么将  $3 \times 3$  卷积核拍平为1维矢量时，不相关的位置补0即可（ $k_{\mathrm{exp}}^{\pm}$  第一列7个红色的0）。将第一列的卷积核复制到第二列时，下移一位，则是对原始图像的右上角卷积运算。以此类推，同样的  $16 \times 1$  卷积核复制4份，分别对准输入的不同位置，即1次性完成了该卷积核的全部运算。

可以看到，上述方案是以较大的硬件代价实现了并行运算，获得时间节省。

思考题：从忆阻突触器件特性的角度，分析上述卷积加速方案实际执行可能存在的哪些问题？

# 2.7 忆阻突触阵列的非理想效应

在前述若干章节，我们讨论过忆阻器用作电子突触时的若干非理想效应以及它们对神经网络计算结果的影响。本节我们针对基于忆阻突触阵列

的卷积神经网络，讨论如何通过“器件-电路-算法”的协同设计，尽可能解决非理想效应对神经形态计算芯片（neuromorphic processing unit，NPU）性能的影响。

![](images/15014dc01832e48c37314099d9ed2e695a86e4bd4bde1c21ea4b5163afb7df2f.jpg)  
图2.8：忆阻突触的非理想效应与解决方案[6]。忆阻突触阵列的非理想效应可分为器件层面与阵列层面。左边显示器件层面的常见非理想效应，包括伏安非线性（I-V nonlinearity）、权重低精度等；右边显示阵列层面的常见非理想效应，包括单元读写噪声（R/W noise）、走线引起的电压衰退（IR-drop）等。

如图2.8所示，从忆阻器件到阵列层面，存在如下非理想效应及其引发的问题：

- 忆阻突触器件的伏安非线性问题（I-V nonlinearity）：理想的忆阻突触电导应该是个常数，即不随读电压的不同而变化。换句话说，忆阻突触器件的伏安特性曲线应该是过原点的一条直线。然而真实的曲线是非线性的，如图2.8左上方所示。它带来一个重大问题是，假如采用电压幅值来编码输入信号，那么对于同一个忆阻突触器件，不同的输入读电压（read voltage）会对应不同的电导值，这将给乘加运算引入误差。

- 忆阻突触器件的精度问题：如图2.8右方所示，输入数据需要首先做数模转换（DAC），变成模拟值编码的电压，送给忆阻突触阵列，所得的输出电流再经过模数转换（ADC）变成数字形式（以便后续计算权重更新）。由于DAC和ADC均可做到很高的精度，因此这个乘加运算的精度上限是由忆阻突触精度决定的。假设忆阻突触的精度是4比特，数模转换转换精度是K比特（K-bit DAC），模数转换精度是L比特（L-bit ADC），当  $\mathrm{K} = 2$ ，则  $\mathrm{L} = 8$  。那么对于14比特的计算精度要求，就必须将输入数据按照DAC的精度K进行比特拆分，多次输入到忆阻阵列中，所得结果通过移位寄存器和累加器（shift register & adder）单元再求和。由于忆阻器的读/写误差，乘加运算结果的低位（low bits）可靠度较差，由图2.8左下方可知，那些左移比较多的乘加运算结果，就会把低位误差移动到高位，造成更大的精度损失。  
- 忆阻突触的读/写噪声问题（R/W noise）：读噪声引起神经网络前向乘加运算的误差，写噪声引起突触权重更新的误差，都会损害神经网络训练与测试的准确度。  
- 阵列走线引起的电压衰减问题（IR-drop）：理论上，图2.8字线的输入电压应该完全施加在忆阻器件上，然而对一个实际阵列，一定会出现图中所示的走线电压降落问题。并且，这个问题会随着阵列规模的增大而愈发严重。

# 2.8 芯片级体系结构

前述章节给出了一种基于忆阻器交叉阵列的卷积神经网络芯片体系结构设计[6]。它的基本特征是铺瓦结构（tile structure），每一个瓦片是一个以忆阻交叉阵列为核心的小型独立处理单元。考虑到同一层卷积运算的各个卷积核是互相独立的，图中所示的铺瓦结构非常适合卷积神经网络运算，即每一个瓦片实现以一个卷积核为核心的运算，各瓦片高度并行。对比图2.8不难发现，这种结构还有效地缓解了走线引起的电压衰减问题。铺瓦结构的其它优点将在后续章节中详细讨论。

# 3 3维忆阻阵列实现

# 3.1 设计理念

近年来，市面上出现了以3D NAND为代表的3维堆叠存储器，这种结构进一步提升了单位面积上集成的器件数量。由此我们很自然地想到，将2维忆阻阵列沿垂直方向堆叠，可以进一步提升忆阻突触阵列的集成度，从而构建更大规模的神经网络。

然而，具体到基于3维忆阻阵列的卷积神经网络实现，是不是简单地把前述章节展示的2维阵列相关设计扩展到3维即可？

答案是否定的。一个首要原因是，如果简单地扩展原2维忆阻突触阵列设计，那么沿垂直方向的每一层都需要做输入输出引线出来，这在工艺上是不实际的。因此，需要革新3维忆阻阵列的结构以及工艺流程，以高效实现神经网络。

另一个问题是，从先前章节的讨论中我们看到，采用2维的忆阻交叉阵列做卷积神经网络的突触矩阵，要么以滚动输入的方式付出较大时间代价，要么将卷积核复制很多份，以较大的硬件代价获取高并行度。假如能够基于3维堆叠的忆阻交叉阵列来设计，应该采用哪一种方案呢？

既然3维堆叠忆阻阵列相比2维的能提供多一个维度的忆阻器硬件，即硬件资源大大丰富，很显然我们应该采取后一种设计，以节省时间代价。

而从前述章节的讨论可以看到，采用这种方案，忆阻阵列中存在大量被浪费的单元，即0电导单元。它们有两个来源，一个是因为需要将原始卷积核拍平为1维矢量，然后做尺寸“扩展”，以精准对准原始图像的相关元素，其中不需要卷积的图像元素对应忆阻突触单元的0电导（蓝色的0）；另一个是将拍平为1维的卷积核复制多份后，需要平移不同的元素距离以对准原始图像不同的区域，而不需要卷积的图像部分则对应忆阻突触单元的0电导（红色的0）。

由上述分析可知，原始图像相对于卷积核越大，两种情况导致的硬件资源浪费就越严重。

如何针对上述两种情况，优化3维堆叠忆阻阵列的设计呢？

第一个拍平问题，正好利用3维堆叠忆阻阵列的输入可以是2维矩阵来

解决。换句话说，原始2维图像无需拍平即可直接输入，而对应的卷积核也是以2维形式存在，这样就避免了两者拍平为1维矢量后，尺寸不同导致的对准冗余问题。

第二个平移问题，如图3.1所示，将卷积核复制若干份，错位排列以后，假如我们能够“斜向”输入原始图像（图中的红/蓝/绿线输入），执行乘加运算，然后沿与该斜向垂直的方向收集计算结果（图中的红/蓝/绿线输出），进一步按图中虚线方框选中忆阻阵列，实际3维堆叠忆阻阵列的生长、制备、连接按照这个虚线方框方向，那么可以看到有两个好处：首先，所有的结果都是在虚线底面给出，方便了卷积输出的统一走线；其次，浪费的边角处忆阻单元数量大大减少。

综上所述，利用3维堆叠忆阻阵列实现卷积神经网络，有两个关键设计点：一个是充分利用3维阵列的输入/输出可以是2维这个特点，将卷积核直接映射到阵列中，对应的原始图像区域也是直接输入，避免了2维阵列设计的“拍平”操作，显著提升了硬件资源利用效率，也降低了外围电路的复杂度；另一个关键点是在复制多份卷积核以提升并行度时，采取层间“斜向”连接的方式，这极大提升了忆阻单元的利用率，同时将输出从同一个底面引出，降低了引线设计难度。

# 3.2 设计与实现实例

J. Joshua Yang与Qiangfei Xia教授团队制备了一种新型的3维忆阻阵列，并在此基础上展示了高效率的卷积神经网络运算[5]。图3.2显示了该方案的设计原理。a图显示要处理的问题：用  $3 \times 3$  的卷积核对  $5 \times 6$  的输入图像做卷积，步长为  $1 \times 1$  ，总共需要20次运算，产生  $3 \times 4$  的特征图。b图和c图是基于2维忆阻阵列的实现方案：首先将卷积核拍平为  $9 \times 1$  的1维列向量，然后将其复制20份；选中的原始图像部分也拍平为同样尺寸，也有20份；一一对准，执行并行处理，得到特征图。

图d显示，如果将图a的20个平面卷积核斜着立起来，那么就可以以并行的方式一次性获得特征图的全部像素计算结果。这里可以把输入想象成  $5 \times 6$  束光，从顶部照射下来，而斜置的卷积“面”对这些光是半透明的，每一个卷积面收集一次光，从最底面输出；而透过该卷积面的光由叠放在下部的卷积面继续收集。

![](images/1a870f598fa7826a72783c8f5200b932ca7ce3c15a79d95745653156d0a6f5dd.jpg)  
图3.1：基于3维堆叠忆阻阵列的斜向对齐卷积运算。图中中括号表示将某个卷积核的某一行  $\{k_{11} k_{21} k_{31}\}^T$  复制三份，沿列方向错位排列，以实现对输入图案不同区域的对准。而输入图案对应的行是  $\{a_{11} a_{21} a_{31} a_{41} a_{51}\}^T$ ，采用斜向输入，分别对  $\{k_{11} k_{21} k_{31}\}^T$  的三个复制品卷积（红/蓝/绿输入箭头），卷积结果从对应的垂直方向输出（红/蓝/绿输出箭头）。以图中虚线框选中卷积单元，实际忆阻阵列按虚线框方向生长、连接。对比中括号选中的原始方案，以及虚线框选中的改进方案，可以看到输入图案的行元素越多，原始方案浪费的忆阻单元越多，而改进方案浪费的边角单元数量几乎不变。

![](images/0638f7265440e6ad4bf546f63a69dc80fbef990225c837e57c0182139c611512.jpg)

![](images/b3f192bde8434aa13e14b3884a4607ae17d2e72d4d81d574a6af0970c9f2d6d2.jpg)

![](images/9c4f82bf1d26c38dc4dfb8a4504810a413eb18d91fcc6c2852f306157d248972.jpg)  
图3.2：基于3维堆叠忆阻阵列的卷积运算示意图[5]。（a）：2维卷积运算操作原理。假设输入是  $5 \times 6$  像素的图像，而卷积核尺寸是  $3 \times 3$  ，那么以 $1 \times 1$  的步长卷积，总共需要12步，得到  $3 \times 4$  尺寸的特征图。（b）和（c)：基于二维忆阻阵列的执行。首先是将2维卷积核拍平成1维列向量（  $9 \times 1$  ），然后将原始图像的各个卷积部分也拍平成同一尺寸的列向量。因此，要么需要将拍平后的1维列向量形式卷积核复制12份，于是12次卷积运算并行执行；要么基于同一个拍平后的卷积核，将原始图像的被卷积部分依次输入。（d）：将（a）图12次卷积运算用到的卷积核立体化示意图。（e）：每一个立体化的卷积核如何映射到3维忆阻阵列中。图中垂直方向的蓝色立柱是金属走线，负责将输入从顶层送到底层；而斜线方向的金色/绿色/紫色圆柱也是走线，它们与垂直方向立柱交叠处即是忆阻突触器件，在这些交叠处，输入电压与忆阻器电导乘积即电流，而从顶层延伸到底层的斜向金属走线将这些电流汇总，上述物理过程在数学上就执行了输入矢量与忆阻矩阵的乘加操作。（f)：进一步展示如何将全部12个卷积核集成到3维忆阻阵列中，并通过最顶面/底面实现直接的2维输入/输出（direct2D I/O）。

![](images/c1bd185afe7320d5284127306997fe1477c0b1e5b1a42be41e75c1f88c2c1e13.jpg)

图e进一步显示对应的忆阻突触阵列与电极设计方式：垂直方向的柱子是金属电极阵列，原始图像由电信号编码后，从柱子顶端输入；斜向柱子与垂直方向柱子交叠处是忆阻器，而斜向柱子本身是金属连线，因此由垂直方向金属柱子输入的电信号经过忆阻器，对应乘加运算中的“乘”，再由斜向金属连线汇总全部电流，对应乘加运算中的“加”；从橙色底电极阵列中相关单元输出的电信号就是一次卷积运算的结果。

图f则是将图e的斜向金属连线以及相应的忆阻单元全部汇总，于是得到三维堆叠忆阻阵列和它内部的走线结构，而顶部和底部则分别是  $5 \times 6$  的2维图像输入和  $3 \times 4$  的2维特征图输出。

图3.3是Yang与Xia课题组设计并制备的3维堆叠忆阻阵列[5]，a是整体结构示意图，总共8层，b和c分别是两个方向的侧视图。图中的垂直红色柱子阵列是电极，负责接入输入信号；蓝色方片是斜向走线；蓝色方片之间的蓝色短柱子是忆阻突触单元，即铂电极/氧化铪功能层/钽电极。从图c可以清楚看到，卷积预算是沿着斜向台阶完成的，计算结果由最底层的黄色电极引出。d图和e图是扫描电镜拍摄的3维阵列侧视图以及剖面图，比例尺分别是2微米与300纳米。

图3.4展示了上述3维堆叠忆阻阵列执行卷积运算的物理过程。首先，输入像素采取二值编码，即0.2V和0V电压分别代表“1”和“0”。忆阻突触也是二值的，1毫西和50微西分别代表“1”和“0”。图b展示了8位2进制输入与对应的忆阻突触按位相乘再相加的结果，从第一行到第四行，输出电流分别应该是：

0.2伏  $\times 1$  毫西  $\times 3 = 600$  微安

0伏  $\times 1$  毫西  $+0.2$  伏  $\times 1$  毫西  $\times 2 = 400$  微安

0伏  $\times 1$  毫西  $\times 2 + 0.2$  伏  $\times 1$  毫西  $= 200$  微安

0伏  $\times 1$  毫西  $\times 3 = 0$  微安

它们分别编码“3”、“2”、“1”、“0”。考虑8位2进制输入总共有256中可能，图c给出了实验测得这256种输入下，相应600微安、400微安、200微安和0微安的电流分布情况。可以看到，这四种电流值分布的交叠很小，也就是对应的模拟值辨识度很高。

上述设计在基于卷积神经网络的手写数字识别（MNIST）以及基于普威特滤波器（Prewitt filters）的图像边缘提取任务均表现良好[5]。

![](images/c7344c09dedecc10e3b6db60c1b534f559793e1a67f45394b890de086b679cc3.jpg)

![](images/ed47ef99e55aaf159f3c26b866e1d7e3ef4017b7ab1a1f7aa134a25ec75cb140.jpg)

![](images/8003da1e1a1252fe86fd86698240c73d7d680d91bfcf42730cf7ff777e58197a.jpg)

![](images/f2235705da8a3f699c4a864d3f9161fe67350ae1b0c116bdda059c97dbd66b16.jpg)  
图3.3: Yang与Xia课题组设计并制备的3维忆阻阵列[5]。(a): 3维阵列结构的示意图。(b)和(c): 从x和y两个方向的侧视图。三个图中红色立柱是金属导线, 负责将输入电压信号沿着垂直方向z逐层往下传; 蓝色薄片也是金属, 它与红色立柱处的红色薄片交叠处即是忆阻突触功能层; 蓝色立柱负责将电流沿垂直方向z传往下一层; 垂直方向最底层的黄色方块是金属引线, 负责输出总电流。注意b图显示各行阵列（row bank）之间是独立的, 即后续章节会讲到的水平堆叠结构。(d)和(e)图是扫描电镜拍摄的实际8层阵列侧视图和剖面图, 此处比例尺为2微米。(f)是封装后的管脚和外部引线图, 比例尺为40微米。(g)是(f)的管脚与引线键合部分细节放大图, 比例尺为15微米。

![](images/f56689a6e1c995b23b9036c1597fd4252788cf9119a361aca34cc2868f2da444.jpg)

![](images/1c1ae5fe52e73bb7760eb45c7980c0ccfaf3c76d6cf1f609b6072a675038fcba.jpg)  
图3.4：实际3维忆阻阵列的卷积运算[5]。(a)乘加运算示意图：输入由电压信号编码从顶层接入，交叠处忆阻器电导充当突触权重，各处电流斜向求和后，由最底层的金属引线导出。忆阻突触电导为2值编码，1毫西代表“1”，50微西代表“0”，开关比约20，图中垂直方向8层阵列，对应的忆阻突触编码为“10010100”。(b)输入电压为2值编码，0.2伏代表“1”，0伏代表“0”。假设图中4种可能的输入，对应(a)图的忆阻电导，则分别得到输出为0.6毫安、0.4毫安、0.2毫安、0毫安，对应输出编码为“3”、“2”、“1”、“0”。(c)图是针对多种输入电压矢量得到的实际输出电流值分布情况。

![](images/863c31fdd0369917ce5383b3961c909221f84b9ee4970d792c0d26ad685f3aec.jpg)

# 4 本章小结

深度卷积神经网络是目前距离应用落地最近的一类神经网络，它在某些图像识别任务的表现已超过了人类，例如在医学图像诊断领域的进展尤其引人注目。然而，代价是它对硬件算力提出了空前的要求。以2015年微软公司针对Imagnet图像数据集发布的神经网络为例，它包含约50层隐藏层，需要配备多达上百颗采用先进工艺的图像处理器（graphic processing unit，GPU），且内存和带宽需求都在TB和TB/s量级。

基于存内计算、高并行度等优势，忆阻器交叉阵列有可能为卷积神经网络提供一种大规模、高能效的硬件执行方案。本章我们依次讨论了基于2维和3维忆阻器交叉阵列的方案。

本章讨论的核心问题是如何从硬件层面提升卷积运算的并行度。对于2维忆阻器交叉阵列，方案是将一个卷积核拍平为1维后，复制多份，并在复制过程中考虑卷积核与输入图像被卷积部分的对准问题，然后映射到忆阻阵列的电导。接下来，将拍平成1维的图像输入，就可以高并行度完成多次卷积运算。

然而，上述方案存在着阵列低利用率的问题：将2维卷积核与输入图像拍平成1维时，由于双方原始尺寸不一致，为了实现像素级对准，忆阻器阵列中相当比例的单元被空置、浪费了。

上述问题的关键在于，对一个卷积核来说，待卷积的图像是很多个2维的同尺寸单元，将这些单元排列起来，实际上是三维的，其中第3个维度是小单元的个数。而可供映射的忆阻器阵列是2维的。双方维度是不匹配的，因此需要降维操作，也就是上述的拍平，由此引发了对准空缺问题。

有鉴于此，一种基于3维忆阻器阵列的方案被提出来。形象地说，它的设计就像沙漠中的太阳能发电站，将完整的原始图像像太阳光一样从三维忆阻阵列的顶部平面输入，而一个个的卷积核就像一面面太阳能面板一样斜立在空间中，运算结果也就是收集的太阳能从底部统一布线引出。这种设计不再需要人为的降维，因此大大提升了阵列单元的利用率。

# 参考文献

[1] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classification with deep convolutional neural networks. In Proceedings of the 25th International Conference on Neural Information Processing Systems - Volume 1, NIPS'12, page 1097-1105, Red Hook, NY, USA, 2012. Curran Associates Inc.  
[2] Ross Girshick, Jeff Donahue, Trevor Darrell, and Jitendra Malik. Rich feature hierarchies for accurate object detection and semantic segmentation. In 2014 IEEE Conference on Computer Vision and Pattern Recognition, pages 580-587, 2014.  
[3] Matthew D. Zeiler and Rob Fergus. Visualizing and understanding convolutional networks. In David Fleet, Tomas Pajdla, Bernt Schiele, and Tinne Tuytelaars, editors, Computer Vision - ECCV 2014, pages 818-833, Cham, 2014. Springer International Publishing.  
[4] Jason Yosinski, Jeff Clune, Anh Nguyen, Thomas Fuchs, and Hod Lipson. Understanding neural networks through deep visualization, 2015.  
[5] Peng Lin, Can Li, Zhongrui Wang, Yunning Li, Hao Jiang, Henhao Song, Mingyi Rao, Ye Zhuo, Navnidhi K. Upadhyay, Mark Barnell, Qing Wu, J. Joshua Yang, and Qiangfei Xia. Three-dimensional memristor circuits as complex neural networks. Nature Electronics, 3(4):225-232, 2020.  
[6] W. Zhang, X. Peng, H. Wu, B. Gao, H. He, Y. Zhang, S. Yu, and H. Qian. Design guidelines of rram based neural-processing-unit: A joint device-circuit-algorithm analysis. In 2019 56th ACM/IEEE Design Automation Conference (DAC), pages 1-6, June 2019.  
[7] C. Yakopcic, M. Z. Alom, and T. M. Taha. Memristor crossbar deep network implementation based on a convolutional neural network. In 2016 International Joint Conference on Neural Networks (IJCNN), pages 963–970, July 2016.

[8] C. Yakopcic, M. Z. Alom, and T. M. Taha. Extremely parallel memristor crossbar architecture for convolutional neural network implementation. In 2017 International Joint Conference on Neural Networks (IJCNN), pages 1696-1703, May 2017.